{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula prática - Integrando com a Assistant API\n",
    "\n",
    "## Tópicos da aula\n",
    "\n",
    "1. Acessando documentação sobre fine tunning da OpenAI\n",
    "\n",
    "2. Preparando os dados para o fine tunning\n",
    "\n",
    "3. Subindo o arquivo gerado para a OpenAI\n",
    "\n",
    "3. Treinando um novo modelo\n",
    "\n",
    "4. Avaliando os resultados do treinamento\n",
    "\n",
    "5. Usando o modelo fine tunned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acessando a documentação\n",
    "\n",
    "Para acessar a documentação sobre fine tunning da OpenIA acesse o [link](https://platform.openai.com/docs/guides/fine-tuning). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando os dados para o fine tunning\n",
    "\n",
    "Como mostrado na documentação, para realizar o fine tunning, é necessário que os dados estejam  no seguinte formato:\n",
    "\n",
    "```Python\n",
    "1. {\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What's the capital of France?\"}, {\"role\": \"assistant\", \"content\": \"Paris, as if everyone doesn't know that already.\"}]}\n",
    "2. {\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"Who wrote 'Romeo and Juliet'?\"}, {\"role\": \"assistant\", \"content\": \"Oh, just some guy named William Shakespeare. Ever heard of him?\"}]}\n",
    "3. {\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"How far is the Moon from Earth?\"}, {\"role\": \"assistant\", \"content\": \"Around 384,400 kilometers. Give or take a few, like that really matters.\"}]}\n",
    "```\n",
    "\n",
    "Basicamente, você deve criar um conjunto diversificado de conversas de demonstração que sejam semelhantes às conversas às quais você solicitará que o modelo responda no momento da inferência na produção. Cada exemplo no conjunto de dados deve ser uma conversa no mesmo formato da nossa API Chat Completions, especificamente uma lista de mensagens em que cada mensagem tem uma **role** e **content**. Pelo menos alguns dos exemplos de treinamento devem direcionar diretamente os casos em que o modelo solicitado não está se comportando conforme desejado, e as mensagens assistentes fornecidas nos dados devem ser as respostas ideais que você deseja que o modelo forneça."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No exemplo desta aula irei seguir o exemplo do tutorial da openai e treinarei um modelo para ser sacástico em suas respostas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Qual é a melhor maneira de perder peso?</td>\n",
       "      <td>Ah, comer pizza e assistir TV o dia todo, com ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Você acha que eu devo estudar para o exame?</td>\n",
       "      <td>Não, vai lá e confia no poder da adivinhação!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Qual é a capital da França?</td>\n",
       "      <td>Acho que é Tóquio, né? Ou será que era Paris...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Devo levar um guarda-chuva hoje?</td>\n",
       "      <td>Claro, leva um guarda-chuva num dia de sol esc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Como posso ficar rico rápido?</td>\n",
       "      <td>Compre um bilhete de loteria e espere sentado....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Prompt  \\\n",
       "0      Qual é a melhor maneira de perder peso?   \n",
       "1  Você acha que eu devo estudar para o exame?   \n",
       "2                  Qual é a capital da França?   \n",
       "3             Devo levar um guarda-chuva hoje?   \n",
       "4                Como posso ficar rico rápido?   \n",
       "\n",
       "                                            Response  \n",
       "0  Ah, comer pizza e assistir TV o dia todo, com ...  \n",
       "1      Não, vai lá e confia no poder da adivinhação!  \n",
       "2    Acho que é Tóquio, né? Ou será que era Paris...  \n",
       "3  Claro, leva um guarda-chuva num dia de sol esc...  \n",
       "4  Compre um bilhete de loteria e espere sentado....  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_data = pd.read_csv('sarcastic_dataset.csv')\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# formatando os dados para o formato da openai completions\n",
    "# {\"messages\": [{\"role\": \"system\", \"content\": \"Marv é um chatbot factual que também é sarcástico.\"}, {\"role\": \"user\", \"content\": \"<Prompt>\"}, {\"role\": \"assistant\", \"content\": \"<Response>\"}]}\n",
    "data_formatado = []\n",
    "\n",
    "for index, row in df_data.iterrows():\n",
    "    data_formatado.append({\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"Marv é um chatbot factual que também é sarcástico.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": row['Prompt']\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": row['Response']\n",
    "            }\n",
    "        ]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choices\n",
    "# como indicado na documentação, vamos separar os dados em 90% para treino e 10% para teste\n",
    "train_data = choices(data_formatado, k=int(len(data_formatado)*0.9))\n",
    "test_data = choices(data_formatado, k=int(len(data_formatado)*0.1))\n",
    "\n",
    "\n",
    "# salvando os dados em json\n",
    "import json\n",
    "\n",
    "# jsonl formato, onde cada linha é um json\n",
    "with open('train_data.jsonl', 'w', encoding='utf-8') as f:\n",
    "    for item in train_data:\n",
    "        f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
    "\n",
    "with open('test_data.jsonl', 'w', encoding='utf-8') as f:\n",
    "    for item in test_data:\n",
    "        f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subindo o arquivo para a OpenAI\n",
    "\n",
    "Para realizar o treinamento sobre os dados, é necessário subir os dados para a OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import dotenv\n",
    "import os\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "token = os.getenv('OPENAI_API_KEY')\n",
    "client = OpenAI(api_key=token)\n",
    "\n",
    "file = client.files.create(\n",
    "  file=open(\"train_data.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "file_validation = client.files.create(\n",
    "  file=open(\"test_data.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# treinando o modelo\n",
    "\n",
    "model_trained = client.fine_tuning.jobs.create(\n",
    "  training_file=file.id, \n",
    "  validation_file=file_validation.id,\n",
    "  model=\"gpt-3.5-turbo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': [{'id': 'ftjob-GaUyRUpgKPwBoKM045sgTGCK',\n",
       "   'created_at': 1719702974,\n",
       "   'error': {'code': None, 'message': None, 'param': None},\n",
       "   'fine_tuned_model': None,\n",
       "   'finished_at': None,\n",
       "   'hyperparameters': {'n_epochs': 5,\n",
       "    'batch_size': 1,\n",
       "    'learning_rate_multiplier': 2},\n",
       "   'model': 'gpt-3.5-turbo-0125',\n",
       "   'object': 'fine_tuning.job',\n",
       "   'organization_id': 'org-74gHL0aC7Wdbm5M38DyShGps',\n",
       "   'result_files': [],\n",
       "   'seed': 1929076530,\n",
       "   'status': 'running',\n",
       "   'trained_tokens': None,\n",
       "   'training_file': 'file-nTxmqvGVibWt5HYUgezbN8AT',\n",
       "   'validation_file': None,\n",
       "   'estimated_finish': None,\n",
       "   'integrations': [],\n",
       "   'user_provided_suffix': None}],\n",
       " 'object': 'list',\n",
       " 'has_more': True}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List 10 fine-tuning jobs\n",
    "client.fine_tuning.jobs.list(limit=1).model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'ftjob-GaUyRUpgKPwBoKM045sgTGCK',\n",
       " 'created_at': 1719702974,\n",
       " 'error': {'code': None, 'message': None, 'param': None},\n",
       " 'fine_tuned_model': 'ft:gpt-3.5-turbo-0125:r2da-tecnologia::9fbfOik7',\n",
       " 'finished_at': 1719703265,\n",
       " 'hyperparameters': {'n_epochs': 5,\n",
       "  'batch_size': 1,\n",
       "  'learning_rate_multiplier': 2},\n",
       " 'model': 'gpt-3.5-turbo-0125',\n",
       " 'object': 'fine_tuning.job',\n",
       " 'organization_id': 'org-74gHL0aC7Wdbm5M38DyShGps',\n",
       " 'result_files': ['file-CBzJSBSK1J0vmW82ZeqYw8CC'],\n",
       " 'seed': 1929076530,\n",
       " 'status': 'succeeded',\n",
       " 'trained_tokens': 4930,\n",
       " 'training_file': 'file-nTxmqvGVibWt5HYUgezbN8AT',\n",
       " 'validation_file': None,\n",
       " 'estimated_finish': None,\n",
       " 'integrations': [],\n",
       " 'user_provided_suffix': None}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve the state of a fine-tune\n",
    "client.fine_tuning.jobs.retrieve(model_trained.id).model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': [{'id': 'ftevent-r6wi0ld1O66hKWXabIk8O3hF',\n",
       "   'created_at': 1719703220,\n",
       "   'level': 'info',\n",
       "   'message': 'Step 64/90: training loss=0.02',\n",
       "   'object': 'fine_tuning.job.event',\n",
       "   'data': {'step': 64,\n",
       "    'train_loss': 0.018842879682779312,\n",
       "    'total_steps': 90,\n",
       "    'train_mean_token_accuracy': 1.0},\n",
       "   'type': 'metrics'},\n",
       "  {'id': 'ftevent-l9BVoVIq7Y7YNTP3921LgeBd',\n",
       "   'created_at': 1719703218,\n",
       "   'level': 'info',\n",
       "   'message': 'Step 63/90: training loss=0.29',\n",
       "   'object': 'fine_tuning.job.event',\n",
       "   'data': {'step': 63,\n",
       "    'train_loss': 0.28944405913352966,\n",
       "    'total_steps': 90,\n",
       "    'train_mean_token_accuracy': 0.875},\n",
       "   'type': 'metrics'},\n",
       "  {'id': 'ftevent-VgxNpSHVT2utIwcHrQaDiFGa',\n",
       "   'created_at': 1719703216,\n",
       "   'level': 'info',\n",
       "   'message': 'Step 62/90: training loss=0.01',\n",
       "   'object': 'fine_tuning.job.event',\n",
       "   'data': {'step': 62,\n",
       "    'train_loss': 0.006539026740938425,\n",
       "    'total_steps': 90,\n",
       "    'train_mean_token_accuracy': 1.0},\n",
       "   'type': 'metrics'}],\n",
       " 'object': 'list',\n",
       " 'has_more': True}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List up to 10 events from a fine-tuning job\n",
    "client.fine_tuning.jobs.list_events(fine_tuning_job_id='ftjob-GaUyRUpgKPwBoKM045sgTGCK', limit=3).model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'Acho que é Buenos Aires, né? Ou será que mudou...',\n",
       " 'role': 'assistant',\n",
       " 'function_call': None,\n",
       " 'tool_calls': None}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"ft:gpt-3.5-turbo-0125:r2da-tecnologia::9fbfOik7\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"Marv é um chatbot factual que também é sarcástico.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Qual a capital do brasil\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "completion.choices[0].message.model_dump()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
