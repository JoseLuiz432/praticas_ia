{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f59262b9-92ea-41ad-a33b-836d67f1c7fd",
   "metadata": {},
   "source": [
    "# Aviso\n",
    "Este notebook é inspirado no codigo disponiblizado em (amazon-sagemaker-examples )[https://github.com/aws/amazon-sagemaker-examples/blob/default/%20%20%20%20%20%20build_and_train_models/sm-hyperparameter_tuning_pytorch/sm-hyperparameter_tuning_pytorch.ipynb]. E **contém algumas modificações**\n",
    "# Conteúdo do notebook\n",
    "1. Contexto\n",
    "2. Configuração\n",
    "3. Dados\n",
    "4. Treinamento\n",
    "5. Host\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd05d6e7-45f3-4839-8616-f4c1e9a74502",
   "metadata": {},
   "source": [
    "## Contexto\n",
    "\n",
    "O MNIST é um conjunto de dados amplamente utilizado para classificação de dígitos manuscritos. Ele consiste em 70.000 imagens rotuladas em escala de cinza, com resolução de 28x28 pixels, de dígitos manuscritos. O conjunto de dados é dividido em 60.000 imagens de treinamento e 10.000 imagens de teste. Existem 10 classes (uma para cada um dos 10 dígitos). Este tutorial mostrará como treinar e testar um modelo MNIST no SageMaker usando PyTorch. Ele também demonstra como usar o SageMaker Automatic Model Tuning para selecionar hiperparâmetros apropriados, a fim de obter o melhor modelo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c2f97a-e02d-439a-a779-718a2bfec01c",
   "metadata": {},
   "source": [
    "# Configuração\n",
    "O notebook original foi criado e testado em uma instância de notebook ml.m4.xlarge. O  nosso teste vai ocorrer em uma ml.t3.medium\n",
    "\n",
    "Vamos começar criando uma sessão no SageMaker e especificando:\n",
    "\n",
    "    - O bucket S3 e o prefixo que você deseja usar para os dados de treinamento e modelo. Isso deve estar na mesma região da instância de notebook, treinamento e hospedagem.\n",
    "    - O ARN da função IAM usada para fornecer acesso de treinamento e hospedagem aos seus dados. Consulte a documentação para saber como criar essas funções. Nota: se mais de uma função for necessária para instâncias de notebook, treinamento e/ou hospedagem, substitua o sagemaker.get_execution_role() pela(s) string(s) completa(s) apropriada(s) do ARN da função IAM.\n",
    "\n",
    "    - Se você quiser usar um bucket S3 específico o nome do bucket deve iniciar com a palavra \"sagemaker\" e ser globalmente exclusivo. Além disso, o bucket deve estar na mesma região da AWS que a instância de notebook usada neste exemplo.\n",
    "\n",
    "Obs.: **Caso não queira usar seu próprio bucket, o SageMaker vai criar um para você. Para isso remova o default_bucket do sagemaker.Session**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4269abe4-5843-470e-87af-9305dc383ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker.tuner import (\n",
    "    IntegerParameter,\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner,\n",
    ")\n",
    "sagemaker_session = sagemaker.Session(default_bucket=\"sagemaker-teste-aula-pratica\")\n",
    "\n",
    "# sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "region = sagemaker_session.boto_region_name\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = \"sagemaker/demo_mnist\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a5a00c-d7b1-4eb3-80d1-ddd8c9198c98",
   "metadata": {},
   "source": [
    "## Dados\n",
    "\n",
    "Download do dataset e inserindo no bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e282f824-108f-409f-b5d7-3fc96d100d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Carregando o dataset MNIST\n",
    "train_dataset = MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "test_dataset = MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=10, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=10, shuffle=False)\n",
    "\n",
    "# Visualizando algumas imagens do dataset MNIST\n",
    "examples = enumerate(train_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "\n",
    "fig, axs = plt.subplots(1, 6, figsize=(15, 3))\n",
    "for i in range(6):\n",
    "    axs[i].imshow(example_data[i][0], cmap='gray')\n",
    "    axs[i].set_title(f'Label: {example_targets[i].item()}')\n",
    "    axs[i].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d7b5d17-8d68-4a76-aa35-0c6f6e08129d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input spec (in this case, just an S3 path): s3://sagemaker-teste-aula-pratica/sagemaker/demo_mnist\n"
     ]
    }
   ],
   "source": [
    "inputs = sagemaker_session.upload_data(path=\"data\", bucket=bucket, key_prefix=prefix)\n",
    "print(\"input spec (in this case, just an S3 path): {}\".format(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f9a435-331e-4f55-9bbd-8d5693603526",
   "metadata": {},
   "source": [
    "## Treinamento\n",
    "Script de treinamento\n",
    "\n",
    "O script mnist.py fornece todo o código necessário para treinar e hospedar um modelo no SageMaker (a função model_fn carrega o modelo). O script de treinamento é muito semelhante a um script de treinamento que você executaria fora do SageMaker, mas você pode acessar propriedades úteis sobre o ambiente de treinamento por meio de várias variáveis de ambiente, como:\n",
    "\n",
    "    SM_MODEL_DIR: Uma string que representa o caminho para o diretório onde os artefatos do modelo serão gravados. Esses artefatos são enviados ao S3 para hospedagem do modelo.\n",
    "    SM_NUM_GPUS: O número de GPUs disponíveis no contêiner atual.\n",
    "    SM_CURRENT_HOST: O nome do contêiner atual na rede de contêineres.\n",
    "    SM_HOSTS: Lista codificada em JSON contendo todos os hosts.\n",
    "\n",
    "Supondo que um canal de entrada, 'training', tenha sido usado na chamada para o método fit(), o seguinte será configurado, seguindo o formato SM_CHANNEL_[nome_do_canal]:\n",
    "\n",
    "    SM_CHANNEL_TRAINING: Uma string que representa o caminho para o diretório que contém os dados no canal 'training'.\n",
    "\n",
    "Para mais informações sobre variáveis de ambiente de treinamento, visite SageMaker Containers.\n",
    "\n",
    "Um script de treinamento típico carrega dados dos canais de entrada, configura o treinamento com hiperparâmetros, treina um modelo e salva o modelo em model_dir para que possa ser hospedado posteriormente. Os hiperparâmetros são passados ao seu script como argumentos e podem ser recuperados com uma instância do argparse.ArgumentParser.\n",
    "\n",
    "Como o SageMaker importa o script de treinamento, você deve colocar seu código de treinamento dentro de um main guard (if __name__ == '__main__':) se estiver usando o mesmo script para hospedar o modelo, como fazemos neste exemplo. Isso evita que o SageMaker execute inadvertidamente seu código de treinamento no momento errado da execução.\n",
    "\n",
    "Por exemplo, o script executado por este notebook seria:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df92def1-4bb3-4af5-954c-9ffa4c77e930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mlogging\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msys\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdistributed\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mdist\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnn\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnn\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mfunctional\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mF\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36moptim\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36moptim\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mutils\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdata\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mutils\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdata\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdistributed\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtorchvision\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m datasets, transforms\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "logger = logging.getLogger(\u001b[31m__name__\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "logger.setLevel(logging.DEBUG)\u001b[37m\u001b[39;49;00m\n",
      "logger.addHandler(logging.StreamHandler(sys.stdout))\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m# Based on https://github.com/pytorch/examples/blob/master/mnist/main.py\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mNet\u001b[39;49;00m(nn.Module):\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32m__init__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36msuper\u001b[39;49;00m(Net, \u001b[36mself\u001b[39;49;00m).\u001b[32m__init__\u001b[39;49;00m()\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.conv1 = nn.Conv2d(\u001b[34m1\u001b[39;49;00m, \u001b[34m10\u001b[39;49;00m, kernel_size=\u001b[34m5\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.conv2 = nn.Conv2d(\u001b[34m10\u001b[39;49;00m, \u001b[34m20\u001b[39;49;00m, kernel_size=\u001b[34m5\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.conv2_drop = nn.Dropout2d()\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.fc1 = nn.Linear(\u001b[34m320\u001b[39;49;00m, \u001b[34m50\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.fc2 = nn.Linear(\u001b[34m50\u001b[39;49;00m, \u001b[34m10\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mforward\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, x):\u001b[37m\u001b[39;49;00m\n",
      "        x = F.relu(F.max_pool2d(\u001b[36mself\u001b[39;49;00m.conv1(x), \u001b[34m2\u001b[39;49;00m))\u001b[37m\u001b[39;49;00m\n",
      "        x = F.relu(F.max_pool2d(\u001b[36mself\u001b[39;49;00m.conv2_drop(\u001b[36mself\u001b[39;49;00m.conv2(x)), \u001b[34m2\u001b[39;49;00m))\u001b[37m\u001b[39;49;00m\n",
      "        x = x.view(-\u001b[34m1\u001b[39;49;00m, \u001b[34m320\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        x = F.relu(\u001b[36mself\u001b[39;49;00m.fc1(x))\u001b[37m\u001b[39;49;00m\n",
      "        x = F.dropout(x, training=\u001b[36mself\u001b[39;49;00m.training)\u001b[37m\u001b[39;49;00m\n",
      "        x = \u001b[36mself\u001b[39;49;00m.fc2(x)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m F.log_softmax(x, dim=\u001b[34m1\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_get_train_data_loader\u001b[39;49;00m(batch_size, training_dir, is_distributed, **kwargs):\u001b[37m\u001b[39;49;00m\n",
      "    logger.info(\u001b[33m\"\u001b[39;49;00m\u001b[33mGet train data loader\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    dataset = datasets.MNIST(\u001b[37m\u001b[39;49;00m\n",
      "        training_dir,\u001b[37m\u001b[39;49;00m\n",
      "        train=\u001b[34mTrue\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        transform=transforms.Compose(\u001b[37m\u001b[39;49;00m\n",
      "            [transforms.ToTensor(), transforms.Normalize((\u001b[34m0.1307\u001b[39;49;00m,), (\u001b[34m0.3081\u001b[39;49;00m,))]\u001b[37m\u001b[39;49;00m\n",
      "        ),\u001b[37m\u001b[39;49;00m\n",
      "        download=\u001b[34mTrue\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "    train_sampler = (\u001b[37m\u001b[39;49;00m\n",
      "        torch.utils.data.distributed.DistributedSampler(dataset) \u001b[34mif\u001b[39;49;00m is_distributed \u001b[34melse\u001b[39;49;00m \u001b[34mNone\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mreturn\u001b[39;49;00m torch.utils.data.DataLoader(\u001b[37m\u001b[39;49;00m\n",
      "        dataset,\u001b[37m\u001b[39;49;00m\n",
      "        batch_size=batch_size,\u001b[37m\u001b[39;49;00m\n",
      "        shuffle=train_sampler \u001b[35mis\u001b[39;49;00m \u001b[34mNone\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        sampler=train_sampler,\u001b[37m\u001b[39;49;00m\n",
      "        **kwargs\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_get_test_data_loader\u001b[39;49;00m(test_batch_size, training_dir, **kwargs):\u001b[37m\u001b[39;49;00m\n",
      "    logger.info(\u001b[33m\"\u001b[39;49;00m\u001b[33mGet test data loader\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mreturn\u001b[39;49;00m torch.utils.data.DataLoader(\u001b[37m\u001b[39;49;00m\n",
      "        datasets.MNIST(\u001b[37m\u001b[39;49;00m\n",
      "            training_dir,\u001b[37m\u001b[39;49;00m\n",
      "            train=\u001b[34mFalse\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "            transform=transforms.Compose(\u001b[37m\u001b[39;49;00m\n",
      "                [transforms.ToTensor(), transforms.Normalize((\u001b[34m0.1307\u001b[39;49;00m,), (\u001b[34m0.3081\u001b[39;49;00m,))]\u001b[37m\u001b[39;49;00m\n",
      "            ),\u001b[37m\u001b[39;49;00m\n",
      "            download=\u001b[34mTrue\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        ),\u001b[37m\u001b[39;49;00m\n",
      "        batch_size=test_batch_size,\u001b[37m\u001b[39;49;00m\n",
      "        shuffle=\u001b[34mTrue\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        **kwargs\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_average_gradients\u001b[39;49;00m(model):\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Gradient averaging.\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    size = \u001b[36mfloat\u001b[39;49;00m(dist.get_world_size())\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mfor\u001b[39;49;00m param \u001b[35min\u001b[39;49;00m model.parameters():\u001b[37m\u001b[39;49;00m\n",
      "        dist.all_reduce(param.grad.data, op=dist.reduce_op.SUM, group=\u001b[34m0\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        param.grad.data /= size\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mtrain\u001b[39;49;00m(args):\u001b[37m\u001b[39;49;00m\n",
      "    is_distributed = \u001b[36mlen\u001b[39;49;00m(args.hosts) > \u001b[34m1\u001b[39;49;00m \u001b[35mand\u001b[39;49;00m args.backend \u001b[35mis\u001b[39;49;00m \u001b[35mnot\u001b[39;49;00m \u001b[34mNone\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    logger.debug(\u001b[33m\"\u001b[39;49;00m\u001b[33mDistributed training - \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(is_distributed))\u001b[37m\u001b[39;49;00m\n",
      "    use_cuda = args.num_gpus > \u001b[34m0\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    logger.debug(\u001b[33m\"\u001b[39;49;00m\u001b[33mNumber of gpus available - \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(args.num_gpus))\u001b[37m\u001b[39;49;00m\n",
      "    kwargs = {\u001b[33m\"\u001b[39;49;00m\u001b[33mnum_workers\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: \u001b[34m1\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mpin_memory\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: \u001b[34mTrue\u001b[39;49;00m} \u001b[34mif\u001b[39;49;00m use_cuda \u001b[34melse\u001b[39;49;00m {}\u001b[37m\u001b[39;49;00m\n",
      "    device = torch.device(\u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m use_cuda \u001b[34melse\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mif\u001b[39;49;00m is_distributed:\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# Initialize the distributed environment.\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        world_size = \u001b[36mlen\u001b[39;49;00m(args.hosts)\u001b[37m\u001b[39;49;00m\n",
      "        os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mWORLD_SIZE\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] = \u001b[36mstr\u001b[39;49;00m(world_size)\u001b[37m\u001b[39;49;00m\n",
      "        host_rank = args.hosts.index(args.current_host)\u001b[37m\u001b[39;49;00m\n",
      "        dist.init_process_group(backend=args.backend, rank=host_rank, world_size=world_size)\u001b[37m\u001b[39;49;00m\n",
      "        logger.info(\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[33m\"\u001b[39;49;00m\u001b[33mInitialized the distributed environment: \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m backend on \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m nodes. \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(\u001b[37m\u001b[39;49;00m\n",
      "                args.backend, dist.get_world_size()\u001b[37m\u001b[39;49;00m\n",
      "            )\u001b[37m\u001b[39;49;00m\n",
      "            + \u001b[33m\"\u001b[39;49;00m\u001b[33mCurrent host rank is \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m. Number of gpus: \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(dist.get_rank(), args.num_gpus)\u001b[37m\u001b[39;49;00m\n",
      "        )\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# set the seed for generating random numbers\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    torch.manual_seed(args.seed)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mif\u001b[39;49;00m use_cuda:\u001b[37m\u001b[39;49;00m\n",
      "        torch.cuda.manual_seed(args.seed)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    train_loader = _get_train_data_loader(args.batch_size, args.data_dir, is_distributed, **kwargs)\u001b[37m\u001b[39;49;00m\n",
      "    test_loader = _get_test_data_loader(args.test_batch_size, args.data_dir, **kwargs)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    logger.debug(\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33mProcesses \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m (\u001b[39;49;00m\u001b[33m{:.0f}\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33m) of train data\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[36mlen\u001b[39;49;00m(train_loader.sampler),\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[36mlen\u001b[39;49;00m(train_loader.dataset),\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[34m100.0\u001b[39;49;00m * \u001b[36mlen\u001b[39;49;00m(train_loader.sampler) / \u001b[36mlen\u001b[39;49;00m(train_loader.dataset),\u001b[37m\u001b[39;49;00m\n",
      "        )\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    logger.debug(\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33mProcesses \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m (\u001b[39;49;00m\u001b[33m{:.0f}\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33m) of test data\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[36mlen\u001b[39;49;00m(test_loader.sampler),\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[36mlen\u001b[39;49;00m(test_loader.dataset),\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[34m100.0\u001b[39;49;00m * \u001b[36mlen\u001b[39;49;00m(test_loader.sampler) / \u001b[36mlen\u001b[39;49;00m(test_loader.dataset),\u001b[37m\u001b[39;49;00m\n",
      "        )\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    model = Net().to(device)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mif\u001b[39;49;00m is_distributed \u001b[35mand\u001b[39;49;00m use_cuda:\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# multi-machine multi-gpu case\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        model = torch.nn.parallel.DistributedDataParallel(model)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34melse\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# single-machine multi-gpu case or single-machine or multi-machine cpu case\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        model = torch.nn.DataParallel(model)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mfor\u001b[39;49;00m epoch \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(\u001b[34m1\u001b[39;49;00m, args.epochs + \u001b[34m1\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "        model.train()\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mfor\u001b[39;49;00m batch_idx, (data, target) \u001b[35min\u001b[39;49;00m \u001b[36menumerate\u001b[39;49;00m(train_loader, \u001b[34m1\u001b[39;49;00m):\u001b[37m\u001b[39;49;00m\n",
      "            data, target = data.to(device), target.to(device)\u001b[37m\u001b[39;49;00m\n",
      "            optimizer.zero_grad()\u001b[37m\u001b[39;49;00m\n",
      "            output = model(data)\u001b[37m\u001b[39;49;00m\n",
      "            loss = F.nll_loss(output, target)\u001b[37m\u001b[39;49;00m\n",
      "            loss.backward()\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[34mif\u001b[39;49;00m is_distributed \u001b[35mand\u001b[39;49;00m \u001b[35mnot\u001b[39;49;00m use_cuda:\u001b[37m\u001b[39;49;00m\n",
      "                \u001b[37m# average gradients manually for multi-machine cpu case only\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "                _average_gradients(model)\u001b[37m\u001b[39;49;00m\n",
      "            optimizer.step()\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[34mif\u001b[39;49;00m batch_idx % args.log_interval == \u001b[34m0\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "                logger.info(\u001b[37m\u001b[39;49;00m\n",
      "                    \u001b[33m\"\u001b[39;49;00m\u001b[33mTrain Epoch: \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m [\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m (\u001b[39;49;00m\u001b[33m{:.0f}\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33m)] Loss: \u001b[39;49;00m\u001b[33m{:.6f}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(\u001b[37m\u001b[39;49;00m\n",
      "                        epoch,\u001b[37m\u001b[39;49;00m\n",
      "                        batch_idx * \u001b[36mlen\u001b[39;49;00m(data),\u001b[37m\u001b[39;49;00m\n",
      "                        \u001b[36mlen\u001b[39;49;00m(train_loader.sampler),\u001b[37m\u001b[39;49;00m\n",
      "                        \u001b[34m100.0\u001b[39;49;00m * batch_idx / \u001b[36mlen\u001b[39;49;00m(train_loader),\u001b[37m\u001b[39;49;00m\n",
      "                        loss.item(),\u001b[37m\u001b[39;49;00m\n",
      "                    )\u001b[37m\u001b[39;49;00m\n",
      "                )\u001b[37m\u001b[39;49;00m\n",
      "        test(model, test_loader, device)\u001b[37m\u001b[39;49;00m\n",
      "    save_model(model, args.model_dir)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mtest\u001b[39;49;00m(model, test_loader, device):\u001b[37m\u001b[39;49;00m\n",
      "    model.eval()\u001b[37m\u001b[39;49;00m\n",
      "    test_loss = \u001b[34m0\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    correct = \u001b[34m0\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mwith\u001b[39;49;00m torch.no_grad():\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mfor\u001b[39;49;00m data, target \u001b[35min\u001b[39;49;00m test_loader:\u001b[37m\u001b[39;49;00m\n",
      "            data, target = data.to(device), target.to(device)\u001b[37m\u001b[39;49;00m\n",
      "            output = model(data)\u001b[37m\u001b[39;49;00m\n",
      "            test_loss += F.nll_loss(output, target, size_average=\u001b[34mFalse\u001b[39;49;00m).item()  \u001b[37m# sum up batch loss\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "            pred = output.max(\u001b[34m1\u001b[39;49;00m, keepdim=\u001b[34mTrue\u001b[39;49;00m)[\u001b[34m1\u001b[39;49;00m]  \u001b[37m# get the index of the max log-probability\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "            correct += pred.eq(target.view_as(pred)).sum().item()\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    test_loss /= \u001b[36mlen\u001b[39;49;00m(test_loader.dataset)\u001b[37m\u001b[39;49;00m\n",
      "    logger.info(\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33mTest set: Average loss: \u001b[39;49;00m\u001b[33m{:.4f}\u001b[39;49;00m\u001b[33m, Accuracy: \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m (\u001b[39;49;00m\u001b[33m{:.0f}\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33m)\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(\u001b[37m\u001b[39;49;00m\n",
      "            test_loss, correct, \u001b[36mlen\u001b[39;49;00m(test_loader.dataset), \u001b[34m100.0\u001b[39;49;00m * correct / \u001b[36mlen\u001b[39;49;00m(test_loader.dataset)\u001b[37m\u001b[39;49;00m\n",
      "        )\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmodel_fn\u001b[39;49;00m(model_dir):\u001b[37m\u001b[39;49;00m\n",
      "    device = torch.device(\u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m torch.cuda.is_available() \u001b[34melse\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    model = torch.nn.DataParallel(Net())\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(os.path.join(model_dir, \u001b[33m\"\u001b[39;49;00m\u001b[33mmodel.pth\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m), \u001b[33m\"\u001b[39;49;00m\u001b[33mrb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\u001b[37m\u001b[39;49;00m\n",
      "        model.load_state_dict(torch.load(f))\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mreturn\u001b[39;49;00m model.to(device)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32msave_model\u001b[39;49;00m(model, model_dir):\u001b[37m\u001b[39;49;00m\n",
      "    logger.info(\u001b[33m\"\u001b[39;49;00m\u001b[33mSaving the model.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    path = os.path.join(model_dir, \u001b[33m\"\u001b[39;49;00m\u001b[33mmodel.pth\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# recommended way from http://pytorch.org/docs/master/notes/serialization.html\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    torch.save(model.cpu().state_dict(), path)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "    parser = argparse.ArgumentParser()\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Data and model checkpoints directories\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33m--batch-size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        default=\u001b[34m64\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        metavar=\u001b[33m\"\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        help=\u001b[33m\"\u001b[39;49;00m\u001b[33minput batch size for training (default: 64)\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33m--test-batch-size\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        default=\u001b[34m1000\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        metavar=\u001b[33m\"\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        help=\u001b[33m\"\u001b[39;49;00m\u001b[33minput batch size for testing (default: 1000)\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33m--epochs\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        default=\u001b[34m10\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        metavar=\u001b[33m\"\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        help=\u001b[33m\"\u001b[39;49;00m\u001b[33mnumber of epochs to train (default: 10)\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33m--lr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m, default=\u001b[34m0.01\u001b[39;49;00m, metavar=\u001b[33m\"\u001b[39;49;00m\u001b[33mLR\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, help=\u001b[33m\"\u001b[39;49;00m\u001b[33mlearning rate (default: 0.01)\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33m--momentum\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m, default=\u001b[34m0.5\u001b[39;49;00m, metavar=\u001b[33m\"\u001b[39;49;00m\u001b[33mM\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, help=\u001b[33m\"\u001b[39;49;00m\u001b[33mSGD momentum (default: 0.5)\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--seed\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m1\u001b[39;49;00m, metavar=\u001b[33m\"\u001b[39;49;00m\u001b[33mS\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, help=\u001b[33m\"\u001b[39;49;00m\u001b[33mrandom seed (default: 1)\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33m--log-interval\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        default=\u001b[34m100\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        metavar=\u001b[33m\"\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        help=\u001b[33m\"\u001b[39;49;00m\u001b[33mhow many batches to wait before logging training status\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33m--backend\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        default=\u001b[34mNone\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        help=\u001b[33m\"\u001b[39;49;00m\u001b[33mbackend for distributed training (tcp, gloo on cpu and gloo, nccl on gpu)\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# Container environment\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--hosts\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mlist\u001b[39;49;00m, default=json.loads(os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_HOSTS\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]))\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--current-host\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_CURRENT_HOST\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--model-dir\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--data-dir\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAINING\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--num-gpus\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mSM_NUM_GPUS\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    train(parser.parse_args())\u001b[37m\u001b[39;49;00m\n"
     ]
    }
   ],
   "source": [
    "!pygmentize mnist.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ec9fea-7f8e-44a1-8125-9827819ba772",
   "metadata": {},
   "source": [
    "## Configurar o trabalho de ajuste de hiperparâmetros\n",
    "\n",
    "**Nota**: com as configurações padrão abaixo, o trabalho de ajuste de hiperparâmetros pode levar cerca de 20 minutos para ser concluído.\n",
    "\n",
    "Agora que preparamos o conjunto de dados e o script, estamos prontos para treinar os modelos. Antes de fazermos isso, é importante destacar que existem muitos hiperparâmetros que podem afetar drasticamente o desempenho dos modelos treinados. Por exemplo, taxa de aprendizado, tamanho do lote (batch size), número de épocas, etc. Como a melhor configuração de hiperparâmetros depende também do conjunto de dados, é quase impossível escolher a melhor configuração sem realizar uma busca. Usando o **SageMaker Automatic Model Tuning**, podemos criar um trabalho de ajuste de hiperparâmetros para encontrar a melhor configuração de forma automatizada e eficiente.\n",
    "\n",
    "Neste exemplo, estamos utilizando o **SageMaker Python SDK** para configurar e gerenciar um trabalho de ajuste de hiperparâmetros. Especificamente, definimos um intervalo ou uma lista de valores possíveis no caso de hiperparâmetros categóricos para cada hiperparâmetro que planejamos ajustar. O trabalho de ajuste de hip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39d636f0-c3e6-49f4-9230-96ff52edbe8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"mnist.py\",\n",
    "    role=role,\n",
    "    py_version=\"py3\",\n",
    "    framework_version=\"1.8.0\",\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.c5.2xlarge\",\n",
    "    hyperparameters={\"epochs\": 1, \"backend\": \"gloo\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "924555cc-fa79-4631-ab35-b7842731401f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: pytorch-training-2024-10-23-18-28-59-685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-23 18:29:02 Starting - Starting the training job...\n",
      "2024-10-23 18:29:17 Starting - Preparing the instances for training...\n",
      "2024-10-23 18:29:51 Downloading - Downloading the training image...\n",
      "2024-10-23 18:30:21 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2024-10-23 18:30:32,016 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2024-10-23 18:30:32,019 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-10-23 18:30:32,028 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2024-10-23 18:30:32,030 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2024-10-23 18:30:32,215 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-10-23 18:30:32,228 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-10-23 18:30:32,239 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-10-23 18:30:32,249 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"backend\": \"gloo\",\n",
      "        \"epochs\": 1\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2024-10-23-18-28-59-685\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-002447664581/pytorch-training-2024-10-23-18-28-59-685/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"mnist\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.c5.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.c5.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"mnist.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"backend\":\"gloo\",\"epochs\":1}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=mnist.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.c5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=mnist\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-002447664581/pytorch-training-2024-10-23-18-28-59-685/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"backend\":\"gloo\",\"epochs\":1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2024-10-23-18-28-59-685\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-002447664581/pytorch-training-2024-10-23-18-28-59-685/source/sourcedir.tar.gz\",\"module_name\":\"mnist\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.c5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"mnist.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--backend\",\"gloo\",\"--epochs\",\"1\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_BACKEND=gloo\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 mnist.py --backend gloo --epochs 1\u001b[0m\n",
      "\u001b[34mDistributed training - False\u001b[0m\n",
      "\u001b[34mNumber of gpus available - 0\u001b[0m\n",
      "\u001b[34mGet train data loader\u001b[0m\n",
      "\u001b[34mUsing downloaded and verified file: /opt/ml/input/data/training/MNIST/raw/train-images-idx3-ubyte.gz\u001b[0m\n",
      "\u001b[34mExtracting /opt/ml/input/data/training/MNIST/raw/train-images-idx3-ubyte.gz to /opt/ml/input/data/training/MNIST/raw\u001b[0m\n",
      "\u001b[34mUsing downloaded and verified file: /opt/ml/input/data/training/MNIST/raw/train-labels-idx1-ubyte.gz\u001b[0m\n",
      "\u001b[34mExtracting /opt/ml/input/data/training/MNIST/raw/train-labels-idx1-ubyte.gz to /opt/ml/input/data/training/MNIST/raw\u001b[0m\n",
      "\u001b[34mUsing downloaded and verified file: /opt/ml/input/data/training/MNIST/raw/t10k-images-idx3-ubyte.gz\u001b[0m\n",
      "\u001b[34mExtracting /opt/ml/input/data/training/MNIST/raw/t10k-images-idx3-ubyte.gz to /opt/ml/input/data/training/MNIST/raw\u001b[0m\n",
      "\u001b[34mUsing downloaded and verified file: /opt/ml/input/data/training/MNIST/raw/t10k-labels-idx1-ubyte.gz\u001b[0m\n",
      "\u001b[34mExtracting /opt/ml/input/data/training/MNIST/raw/t10k-labels-idx1-ubyte.gz to /opt/ml/input/data/training/MNIST/raw\u001b[0m\n",
      "\u001b[34mProcessing...\u001b[0m\n",
      "\u001b[34mDone!\u001b[0m\n",
      "\u001b[34mGet test data loader\u001b[0m\n",
      "\u001b[34mProcesses 60000/60000 (100%) of train data\u001b[0m\n",
      "\u001b[34mProcesses 10000/10000 (100%) of test data\u001b[0m\n",
      "\u001b[34m[2024-10-23 18:30:33.579 algo-1:27 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2024-10-23 18:30:33.751 algo-1:27 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2024-10-23 18:30:33.752 algo-1:27 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2024-10-23 18:30:33.752 algo-1:27 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2024-10-23 18:30:33.752 algo-1:27 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2024-10-23 18:30:33.752 algo-1:27 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2024-10-23 18:30:33.765 algo-1:27 INFO hook.py:584] name:module.conv1.weight count_params:250\u001b[0m\n",
      "\u001b[34m[2024-10-23 18:30:33.765 algo-1:27 INFO hook.py:584] name:module.conv1.bias count_params:10\u001b[0m\n",
      "\u001b[34m[2024-10-23 18:30:33.765 algo-1:27 INFO hook.py:584] name:module.conv2.weight count_params:5000\u001b[0m\n",
      "\u001b[34m[2024-10-23 18:30:33.765 algo-1:27 INFO hook.py:584] name:module.conv2.bias count_params:20\u001b[0m\n",
      "\u001b[34m[2024-10-23 18:30:33.765 algo-1:27 INFO hook.py:584] name:module.fc1.weight count_params:16000\u001b[0m\n",
      "\u001b[34m[2024-10-23 18:30:33.765 algo-1:27 INFO hook.py:584] name:module.fc1.bias count_params:50\u001b[0m\n",
      "\u001b[34m[2024-10-23 18:30:33.765 algo-1:27 INFO hook.py:584] name:module.fc2.weight count_params:500\u001b[0m\n",
      "\u001b[34m[2024-10-23 18:30:33.765 algo-1:27 INFO hook.py:584] name:module.fc2.bias count_params:10\u001b[0m\n",
      "\u001b[34m[2024-10-23 18:30:33.765 algo-1:27 INFO hook.py:586] Total Trainable Params: 21840\u001b[0m\n",
      "\u001b[34m[2024-10-23 18:30:33.765 algo-1:27 INFO hook.py:413] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2024-10-23 18:30:33.768 algo-1:27 INFO hook.py:476] Hook is writing from the hook with pid: 27\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [6400/60000 (11%)] Loss: 2.010908\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [12800/60000 (21%)] Loss: 1.009527\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [19200/60000 (32%)] Loss: 0.877578\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [25600/60000 (43%)] Loss: 0.805486\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [32000/60000 (53%)] Loss: 0.635695\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [38400/60000 (64%)] Loss: 0.505831\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [44800/60000 (75%)] Loss: 0.537033\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [51200/60000 (85%)] Loss: 0.532630\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [57600/60000 (96%)] Loss: 0.428416\u001b[0m\n",
      "\u001b[34mTest set: Average loss: 0.1919, Accuracy: 9424/10000 (94%)\u001b[0m\n",
      "\u001b[34mSaving the model.\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torchvision/datasets/mnist.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:143.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 1 [6400/60000 (11%)] Loss: 2.010908\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 1 [12800/60000 (21%)] Loss: 1.009527\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 1 [19200/60000 (32%)] Loss: 0.877578\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 1 [25600/60000 (43%)] Loss: 0.805486\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 1 [32000/60000 (53%)] Loss: 0.635695\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 1 [38400/60000 (64%)] Loss: 0.505831\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 1 [44800/60000 (75%)] Loss: 0.537033\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 1 [51200/60000 (85%)] Loss: 0.532630\u001b[0m\n",
      "\u001b[34mINFO:__main__:Train Epoch: 1 [57600/60000 (96%)] Loss: 0.428416\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\u001b[0m\n",
      "\u001b[34mINFO:__main__:Test set: Average loss: 0.1919, Accuracy: 9424/10000 (94%)\u001b[0m\n",
      "\u001b[34mINFO:__main__:Saving the model.\u001b[0m\n",
      "\u001b[34m2024-10-23 18:30:47,172 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2024-10-23 18:31:05 Uploading - Uploading generated training model\n",
      "2024-10-23 18:31:05 Completed - Training job completed\n",
      "Training seconds: 89\n",
      "Billable seconds: 89\n"
     ]
    }
   ],
   "source": [
    "# test training job\n",
    "\n",
    "estimator.fit({\"training\": inputs})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa4c682-7518-4ca8-96ad-65f600d106b0",
   "metadata": {},
   "source": [
    "Uma vez que definimos nosso estimador, podemos especificar os hiperparâmetros que gostaríamos de ajustar e seus possíveis valores. Temos três tipos diferentes de hiperparâmetros:\n",
    "\n",
    "1. **Parâmetros categóricos**: precisam assumir um valor de um conjunto discreto. Definimos isso passando a lista de valores possíveis para `CategoricalParameter(list)`.\n",
    "2. **Parâmetros contínuos**: podem assumir qualquer valor real entre o valor mínimo e máximo, definido por `ContinuousParameter(min, max)`.\n",
    "3. **Parâmetros inteiros**: podem assumir qualquer valor inteiro entre o valor mínimo e máximo, definido por `IntegerParameter(min, max)`.\n",
    "\n",
    "**Nota**: se possível, é quase sempre melhor especificar um valor como o tipo menos restritivo. Por exemplo, ajustar a taxa de aprendizado como um valor contínuo entre 0,01 e 0,2 provavelmente resultará em um desempenho melhor do que ajustá-la como um parâmetro categórico com valores 0,01, 0,1, 0,15 ou 0,2. Especificamos o tamanho do lote como um parâmetro categórico aqui, já que é geralmente recomendado que seja uma potência de 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d16f7da-5d61-402c-8bd2-6eb3234b2280",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_ranges = {\n",
    "    \"lr\": ContinuousParameter(0.001, 0.1),\n",
    "    \"batch-size\": CategoricalParameter([32, 64, 128, 256, 512]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9899713b-5ab4-45d4-a70d-67190b170040",
   "metadata": {},
   "source": [
    "Em seguida, vamos especificar a métrica de objetivo que gostaríamos de ajustar e sua definição, que inclui a expressão regular (Regex) necessária para extrair essa métrica dos logs do CloudWatch do trabalho de treinamento. Neste caso específico, nosso script emite o valor da perda média e usaremos isso como a métrica de objetivo. Também definimos o `objective_type` como 'minimize', para que o ajuste de hiperparâmetros busque minimizar a métrica de objetivo ao procurar a melhor configuração de hiperparâmetros. Por padrão, o `objective_type` é definido como 'maximize'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd5fd08c-da8b-4b34-838c-c330d03d144e",
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_metric_name = \"average test loss\"\n",
    "objective_type = \"Minimize\"\n",
    "metric_definitions = [{\"Name\": \"average test loss\", \"Regex\": \"Test set: Average loss: ([0-9\\\\.]+)\"}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6d9939-7824-4ba6-a684-3589ffecfc9b",
   "metadata": {},
   "source": [
    "Agora, vamos criar um objeto `HyperparameterTuner`, ao qual passamos:\n",
    "\n",
    "- O estimador PyTorch que criamos anteriormente.\n",
    "- Nossos intervalos de hiperparâmetros.\n",
    "- O nome e a definição da métrica de objetivo.\n",
    "- Configurações de recursos de ajuste, como o número total de trabalhos de treinamento a serem executados e quantos trabalhos de treinamento podem ser executados em paralelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb88b379-fea0-413c-ab46-13059e4ef96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = HyperparameterTuner(\n",
    "    estimator,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    metric_definitions,\n",
    "    max_jobs=9,\n",
    "    max_parallel_jobs=3,\n",
    "    objective_type=objective_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471f0f98-9d6a-4f71-82ab-dfa783534bd3",
   "metadata": {},
   "source": [
    "## Iniciar o trabalho de ajuste de hiperparâmetros\n",
    "\n",
    "Finalmente, podemos iniciar nosso trabalho de ajuste de hiperparâmetros chamando `.fit()` e passando o caminho do S3 para nosso conjunto de dados de treino e teste.\n",
    "\n",
    "Após a criação do trabalho de ajuste de hiperparâmetros, você poderá descrever o trabalho de ajuste para ver seu progresso no próximo passo. Também pode acessar a console do SageMaker em **Jobs** para acompanhar o progresso do trabalho de ajuste de hiperparâmetros.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4fe018d-bb5c-4129-98c8-b44d3e3d37ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: pytorch-training-241023-1831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................................!\n"
     ]
    }
   ],
   "source": [
    "tuner.fit({\"training\": inputs})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f2ad8f-bc97-44e3-a075-53492966dac2",
   "metadata": {},
   "source": [
    "## Hospedagem\n",
    "#### Criar endpoint\n",
    "\n",
    "Após o treinamento, utilizamos o objeto `tuner` para construir e implantar um `PyTorchPredictor`. Isso cria um **Endpoint SageMaker** — um serviço de previsão hospedado que podemos usar para realizar inferências com base no melhor modelo do `tuner`. Lembre-se de que, nos passos anteriores, o `tuner` lançou vários trabalhos de treinamento durante o ajuste, e o modelo resultante com a melhor métrica de objetivo é definido como o melhor modelo.\n",
    "\n",
    "Conforme mencionado acima, temos a implementação da função `model_fn` no script **mnist.py**, que é necessária. Vamos utilizar as implementações padrão de `input_fn`, `predict_fn`, `output_fn` e `transform_fn` definidas em **sagemaker-pytorch-containers**.\n",
    "\n",
    "Os argumentos da função `deploy` nos permitem definir o número e o tipo de instâncias que serão usadas para o **Endpoint**. Estas não precisam ser as mesmas que utilizamos para o trabalho de treinamento. Por exemplo, você pode treinar um modelo em um conjunto de instâncias baseadas em GPU e, em seguida, implantar o Endpoint em um conjunto de instâncias baseadas em CPU, mas é necessário garantir que você retorne ou salve seu modelo como um modelo para CPU, semelhante ao que fizemos no **mnist.py**. Aqui, vamos implantar o modelo em uma única instância **ml.m4.xlarge**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9ef79d7-7b2e-4020-9495-90c7c54be543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2024-10-23 18:34:38 Starting - Found matching resource for reuse\n",
      "2024-10-23 18:34:38 Downloading - Downloading the training image\n",
      "2024-10-23 18:34:38 Training - Training image download completed. Training in progress.\n",
      "2024-10-23 18:34:38 Uploading - Uploading generated training model\n",
      "2024-10-23 18:34:38 Completed - Resource reused by training job: pytorch-training-241023-1831-008-0aff2ebf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Repacking model artifact (s3://sagemaker-us-east-2-002447664581/pytorch-training-241023-1831-004-ba7a3528/output/model.tar.gz), script artifact (s3://sagemaker-us-east-2-002447664581/pytorch-training-2024-10-23-18-31-16-599/source/sourcedir.tar.gz), and dependencies ([]) into single tar.gz file located at s3://sagemaker-us-east-2-002447664581/pytorch-training-2024-10-23-18-35-42-667/model.tar.gz. This may take some time depending on model size...\n",
      "INFO:sagemaker:Creating model with name: pytorch-training-2024-10-23-18-35-42-667\n",
      "INFO:sagemaker:Creating endpoint-config with name pytorch-training-241023-1831-004-ba7a3528\n",
      "INFO:sagemaker:Creating endpoint with name pytorch-training-241023-1831-004-ba7a3528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------!"
     ]
    }
   ],
   "source": [
    "predictor = tuner.deploy(initial_instance_count=1, instance_type=\"ml.m4.xlarge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebe9ba2-dd99-489e-97e4-7cc48d29d6eb",
   "metadata": {},
   "source": [
    "### Avaliação\n",
    "\n",
    "Agora podemos usar este preditor para classificar dígitos escritos à mão.\n",
    "\n",
    "Você verá uma caixa de imagem vazia após executar a célula abaixo. Em seguida, você pode desenhar um número nela, e os dados de pixel serão carregados em uma variável de dados neste notebook, que podemos então passar para o preditor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ce64fff-a46b-4514-8ab9-12d7cb1ea797",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "data_dir = \"data/MNIST/raw\"\n",
    "with gzip.open(os.path.join(data_dir, \"t10k-images-idx3-ubyte.gz\"), \"rb\") as f:\n",
    "    images = np.frombuffer(f.read(), np.uint8, offset=16).reshape(-1, 28, 28).astype(np.float32)\n",
    "\n",
    "mask = random.sample(range(len(images)), 16)  # randomly select some of the test images\n",
    "mask = np.array(mask, dtype=np.int32)\n",
    "data = images[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3985b97d-a280-442d-9840-f4a75871ae71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxUAAAMWCAYAAACHiaukAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA+sElEQVR4nO3de9zX8/0/8M+lVKIQTY4ZWzN853yOhDGEstXMcfbNoTmMr81v5lAxDMMwX6YxX4elWWxyaphS5pAZE5rTksohoUKk+vz+2O376zdez4/rfb0+n+v6XNd1v//5fPV8f55d1/WqHt63PddQLpfLJQAAgCZarqUHAAAAWjehAgAAyCJUAAAAWYQKAAAgi1ABAABkESoAAIAsQgUAAJBFqAAAALIIFQAAQJaOjf2FDQ0NtZwDWkRT/w/l3QfaIvcBlnEfYJnG3AdvKgAAgCxCBQAAkEWoAAAAsggVAABAFqECAADIIlQAAABZhAoAACCLUAEAAGQRKgAAgCxCBQAAkEWoAAAAsggVAABAFqECAADIIlQAAABZhAoAACCLUAEAAGQRKgAAgCxCBQAAkEWoAAAAsggVAABAFqECAADIIlQAAABZhAoAACCLUAEAAGTp2NIDtAWbb755ePa73/0uWZ8yZUrY88477yTrd9xxR9jz4IMPJuuLFy8OewCgiHK5HJ4tXLgwWd9xxx3Dnqeeeip3JOrQcsul/5v1rbfeGva88MILyfqZZ54Z9vg3Tn3xpgIAAMgiVAAAAFmECgAAIItQAQAAZBEqAACALA3lSqsc/v9f2NBQ61nqwvrrrx+eXXfddcn6DjvsEPYsv/zyhWeIvtaVvlWXX355sn7JJZeEPTNnziw2WBvUyB//z2gv94HKRo4cmayfddZZYc/PfvazZP20006rykw53Af+1ze/+c1kvdL2nmhzYaW/V99///1CczUn96HpxowZk6wPHjw47Jk1a1ayvsUWW4Q9lf79FTnqqKOS9c6dOxd+1i9+8Yvw7J577in8vHrWmPvgTQUAAJBFqAAAALIIFQAAQBahAgAAyCJUAAAAWYQKAAAgi5WynzJhwoTwrG/fvs0yQ1NWykaOPPLI8OzGG28s/Ly2xspAPk+XLl3Cs4ceeihZ33zzzcOe/v37J+sPP/xwoblqwX3gf6233nrJ+vTp08Oejz/+OFnv169f2PP4448Xmqs5uQ+VbbTRRuHZo48+mqx379497Pnggw+S9WhVcalUKq277rrJ+uLFi8Oe6Pta6fvWsWPHZH3JkiVhz4ABA5L18ePHhz31zEpZAACg5oQKAAAgi1ABAABkESoAAIAsQgUAAJAl/T9nb8d23nnn8KwpmyDuu+++ZP3aa68Ne374wx8m61tvvXXhz7/wwgvDswcffDBZnzlzZuHPoW2qtN3jvPPOS9YPPPDAWo3TIrp16xaebbXVVsn6Rx99FPY888wz2TPRMrp27RqenXzyycn6e++9F/ZcffXVyXqljTLNZcaMGYV7OnTokKyvuOKKuePQgtZee+1k/YEHHgh7Km15ikQ/9/Pnzw97Lr300mT9ggsuCHveeuutZL3Shs9o01+lfxdW2kDVVnlTAQAAZBEqAACALEIFAACQRagAAACyCBUAAEAWoQIAAMhipeynTJ06NTzbZJNNkvXjjjsu7Bk9enSyXmlF2rhx45L1K6+8Muz57ne/m6z37Nkz7DnqqKOS9eHDh4c9tC+77757eLbvvvsm6/379w97ojXG9WyDDTYo3NPQ0BCeRes1K/2ZQH349re/HZ6dffbZhZ93yy23JOtz584t/Kxq69OnT+Ged999N1lvjfeeZVZdddVkfc011yz8rEpr7m+88cZk/dlnny38OZVsvPHGyXq/fv0KP+svf/lLeFZp5W5b5U0FAACQRagAAACyCBUAAEAWoQIAAMgiVAAAAFlsf/qUzTbbrKVHKH388cfJ+tChQ8Oe/fbbL1lfffXVw54ePXoUG4w2q0OHDsl69HNVKpVKixYtStbXWGONqsxULwYOHFi4p9Imp9dffz1jGppD3759k/Xrrrsu7CmXy7Uap0XsvPPOyXqlzWaVzmhfoo1flbakffjhh4U/p3Pnzsn6wQcfHPZEG6hWW221sOejjz5K1gcPHlxhuvbHmwoAACCLUAEAAGQRKgAAgCxCBQAAkEWoAAAAsggVAABAFitl24honWFbW3NIbXz3u99N1jfaaKOwZ+TIkcl6W1uZutVWWxXuOe+882owCdW06667hmeXXnppsl7pz9MlS5Yk6z//+c/Dnvfeey88aw4dO8b/BBgyZEiyXulrcNNNN2XPRP3ZY489Cvfce++9yXqlta3R3zfbbLNN2POjH/0oWd9ggw0qTJf28MMPh2fRavG5c+cW/py2zJsKAAAgi1ABAABkESoAAIAsQgUAAJBFqAAAALLY/gTtRKdOncKzPffcM1l/5JFHCn/OxIkTC/c0l1GjRoVnixcvTta32267sGf33XdP1ittEaF5rbnmmsn65ZdfHvZssskmhT8n2vJ02mmnFX5WcznmmGPCs2jjz/PPPx/2nHXWWdkzUX+effbZwj0XXHBBsn7SSSeFPdFdrbYf//jHyfp1110X9tjy1DjeVAAAAFmECgAAIItQAQAAZBEqAACALEIFAACQRagAAACyWCnbjs2ePbulR6AZXXbZZeHZ/vvvn6yPGDEi7LnqqqtyR/p/Bg0aFJ698847yfpLL70U9uywww7J+mGHHRb2LL/88sn622+/HfZMmDAhPKM+XHrppcl6U9bGPvbYY+HZGWecUfh5Le3jjz8u3BPdk1KpVOrQoUPOONSpv//978l6pVWzG2+8cbLelLWxixYtCs/OOeecZP3WW28Ne2bOnJmsf/jhh8UG4zO8qQAAALIIFQAAQBahAgAAyCJUAAAAWYQKAAAgi+1P7dgf//jHlh6BGjjttNOS9R133DHs2WmnnZL1aOtHqVQqlcvlYoOVSqXNN988Wb/22mvDnpVXXjlZ33333cOenXfeOVlvynaa3/72t4V7qB+dO3eu2rOee+658GzJkiVV+5xq6927d7Jeaeta5Atf+EJ4Ft3VefPmFf4c6sebb76ZrP/Hf/xH2PPaa68l62uvvXbhz+/UqVN4Fm1/iuqlUvz32jPPPBP2RHf/wgsvDHvq+c+EWvGmAgAAyCJUAAAAWYQKAAAgi1ABAABkESoAAIAsQgUAAJDFStlW5JhjjgnPevbsmay/+OKLYc8bb7yRPRMt44ADDgjPRo4cmaxXWqc6ceLEZH3u3LlhT7Rm8Gc/+1nYc8cddyTr1113Xdjz7LPPJusPPfRQ2DNhwoRkfcUVVwx7jjzyyGS90spA6t9bb72VrDc0NBR+1ve+973wLPr5qbZo7qaseG6KaG1sqVQqrbDCCs0yA/Vh2LBh4Vml1cMt7Wtf+1qheiV77bVXeHb44Ycn6zNmzCj8Oa2FNxUAAEAWoQIAAMgiVAAAAFmECgAAIItQAQAAZGkoN3JlRFM2ZdA00XaNyZMnhz1f/epXk/Vrr7027Km0Taq9aOrGlJa+Dw8//HB4tv322xd+3ttvv52s77vvvmHPwQcfnKw/8MADYc9dd91VbLAm2nDDDZP1v//972FPly5dkvVKW6b69+9fbLA611rvQyUrrbRSsj5mzJiwp2/fvsl6t27dwp7m2r7U0tufnnvuufBst912S9bnzJlTq3Fqqi3eh6bYaKONkvVnnnkm7Im2Db7yyithz+mnn56sjx8/vsJ0aUOGDAnP1lhjjao9b5NNNgl7XnjhhWT9G9/4Rtgzffr0QnM1p8bcB28qAACALEIFAACQRagAAACyCBUAAEAWoQIAAMgiVAAAAFmslK2xaD3slltuGfZE69uuuOKKwp///PPPh2cjRoxI1seOHVv4c1qr1royMFq9VyqVSieddFKyXmnmkSNHJutN+ZlrLp07dw7PJk6cmKxvs802Yc/777+frEf3sVQqlV5//fXwrDVqrfeh2tZbb71kfa+99gp71llnnWS90jrVrbbaKlm//fbbK0yX1qlTp/DsoosuStaj32cl0arQtsh9+JdNN900Wa+0ojtajRqtHa7UU88q/Xtp0KBByfqvfvWrsGfYsGHZM9WKlbIAAEDNCRUAAEAWoQIAAMgiVAAAAFmECgAAIEvHlh6gNdl8882T9WjbTqlUKvXv3z9ZX3vttcOeaHNEUzZRfPWrXw3PxowZk6xfdtllYc8pp5xSeAaq79xzzw3PRo8enawvt1z83xBeffXV7Jma25VXXhmeRVuerrnmmrDnl7/8ZbLe1jY88flmzJiRrI8aNaqZJ2m8gw46KDyLtjwtWrQo7KnnzW80r4033rhwT7T5qDVueKrk97//fXgWfQ3aMm8qAACALEIFAACQRagAAACyCBUAAEAWoQIAAMgiVAAAAFmslP2UM844Izw79dRTk/WuXbvWapwW8f3vfz88i9aVPvHEE7Uah4JeeeWVlh6hqrp165asH3744YWfVWmd4bPPPlv4eVAvvvOd7xTuqfRnRfT3He3PbrvtVrjn7bffrsEk9efqq69u6RHqijcVAABAFqECAADIIlQAAABZhAoAACCLUAEAAGRpt9ufoi1PZ599dthTLpdrNc6/WW65dNb75z//GfZceeWVyfoqq6wS9vzwhz9M1rt06RL2rLjiiuEZNFWln9OxY8cm6x06dAh7Zs2alaz/8Y9/LDQXtBYPP/xweLbffvsl6w0NDbUaB1qdSn8PHXroocl6pe2f7fF+eVMBAABkESoAAIAsQgUAAJBFqAAAALIIFQAAQBahAgAAyNKmV8puvvnm4dmpp56arFdaG9tcK2Wj1bFbbrll2PPee+9V7fOPP/748GzOnDlV+xzanxVWWCFZ/+53vxv27Lrrrsn6iy++GPYceOCByfq0adPCHmjNop/5Uin+u+v2228Pe3bcccdk/cc//nHYc+KJJybr06dPD3uguW277bbJ+jnnnBP2fP3rXy/8OePHj0/Wo/8LgLbAmwoAACCLUAEAAGQRKgAAgCxCBQAAkEWoAAAAsjSUG7nSqKGhodazVN31118fnh166KHJeqXfZ3NtfzrhhBOS9auuuqqqnxNt4unSpUvY8+6771Z1hpbW1O9pa7wP9eCCCy5I1n/4wx8Wflaln9NPPvmk8PNwH1qDjTbaKFl/7LHHwp6VVlopWZ8xY0bYs9566yXr77zzTtgTbVycNWtW2FPP3Id/Oeyww5L1//mf/wl7Hn744ULPKpVKpQULFiTr3bp1C3t69eqVrA8ePDjsiTabbbfddmFPZMmSJeHZgAEDkvVoK1S9a8x98KYCAADIIlQAAABZhAoAACCLUAEAAGQRKgAAgCxCBQAAkKVjSw9QS5MmTQrPopWyzeU3v/lNeFbt1bGRhQsXFqrD/2/55ZdP1i+++OKw5+ijj07W//a3v4U9Bx10ULK+ePHiCtNB27Taaqsl69Ha2EqitbGlUqn06quvJutbbLFF2DNv3rzCM1D/on9LPfXUU2HPTjvtlKy/8sorYc/06dOT9fXXXz/saS6PPPJIsn7OOeeEPa11dWwObyoAAIAsQgUAAJBFqAAAALIIFQAAQBahAgAAyNJQLpfLjfqFDQ21nqXqVlxxxfDs1FNPTdbPOOOMsCf6UlXalnTwwQcn63/605/Cno8//jg8o7oa+eP/Ga3xPlRbtNlijz32CHtmz56drPfv3z/seemll4oNRpO5D/Wve/fuyfrTTz8d9kTf19tuuy3sOfvss5P1+fPnV5iubXEfKqu0cWz48OHJ+imnnFKrcf7N7373u/Bs3LhxyfqUKVPCnmgbWnv691pj7oM3FQAAQBahAgAAyCJUAAAAWYQKAAAgi1ABAABkESoAAIAsbXqlLHweKwMr69u3b3h2//33J+sTJ04Me/7rv/4rWX/22WeLDUZNuA+wjPsAy1gpCwAA1JxQAQAAZBEqAACALEIFAACQRagAAACy2P5Eu2a7ByzjPsAy7gMsY/sTAABQc0IFAACQRagAAACyCBUAAEAWoQIAAMgiVAAAAFmECgAAIItQAQAAZBEqAACALEIFAACQRagAAACyCBUAAEAWoQIAAMgiVAAAAFmECgAAIItQAQAAZBEqAACALEIFAACQRagAAACyNJTL5XJLDwEAALRe3lQAAABZhAoAACCLUAEAAGQRKgAAgCxCBQAAkEWoAAAAsggVAABAFqECAADIIlQAAABZhAoAACCLUAEAAGQRKgAAgCxCBQAAkEWoAAAAsnRs7C9saGio5RzQIsrlcpP63AfaIvcBlnEfYJnG3AdvKgAAgCxCBQAAkEWoAAAAsggVAABAFqECAADIIlQAAABZhAoAACCLUAEAAGQRKgAAgCxCBQAAkEWoAAAAsggVAABAFqECAADIIlQAAABZhAoAACCLUAEAAGQRKgAAgCxCBQAAkEWoAAAAsggVAABAFqECAADIIlQAAABZhAoAACCLUAEAAGTp2NIDAK3T1VdfnawfffTRVf2c66+/PlmfP39+2DNu3LhkfdKkSWHPokWLCs0FACzjTQUAAJBFqAAAALIIFQAAQBahAgAAyCJUAAAAWRrK5XK5Ub+woaHWs/A59ttvv/DsjjvuSNaPPfbYsOdXv/pV9kytXSN//D/DfSiV+vbtm6z37Nkz7Ln88suT9bXWWqvw51f6HkTf1yuvvDLsueSSS5L16dOnF5qrNXMfYBn3AZZpzH3wpgIAAMgiVAAAAFmECgAAIItQAQAAZBEqAACALEIFAACQxUrZVuSJJ54Iz7bccstk/aWXXgp7+vTpkz1Ta2dlYPVtvfXW4dn48eOT9VVWWSXs2XvvvZP1I488MuwZMmRIeBaJVsfuueeeYc/LL79c+HPqmfsAy7gPsIyVsgAAQM0JFQAAQBahAgAAyCJUAAAAWYQKAAAgi+1PrUilb1V09vjjj4c922+/ffZMrZ3tHpUtv/zy4dl2222XrI8bNy7s6d69e+EZNtxww2R9xowZYc8pp5ySrJ9++ulhT7du3Qp/zi677JKsv/baa2FPPXMfYJn2dB++853vhGfrrrtust65c+ewZ8cdd0zWv/71r4c9yy1Xvf/OXel7EH1fH3jggbBn3333TdYXLVpUbLBWzPYnAACg5oQKAAAgi1ABAABkESoAAIAsQgUAAJBFqAAAALJYKduKNGWl7Pe+972w5/rrr88dqdVrTysDm2LgwIHh2dixY5P1pUuXhj1TpkxJ1j/88MPCM7z//vthTyRaT1sqlUr3339/sr7eeuuFPVdeeWWyHq20LZVKpU8++SQ8a2nVvg+rrbZa2HPooYcm61/84hebNEN7Ed2V6G6VSqXS008/XbXPr/SzPWzYsGS9mqtCm1Nr/fuh0nrYyy67LFlfeeWVw56OHTtmz9Ta3X333cn6wQcfHPYsWLCgVuO0CCtlAQCAmhMqAACALEIFAACQRagAAACyCBUAAEAW/5P+NmLRokXJ+ptvvtnMk9Aabb/99sn6qFGjCj/rJz/5SXh20UUXJeu9evUKe5qy5Sny8ssvh2cHHHBAsv63v/0t7DnuuOOS9RdffDHsueKKK8Kztubxxx8Pz9Zff/3mG6QFVdp8VGlTWmvU1G1JVFeXLl3Cs0ob2Yjts88+yXqlLZpDhw5N1t99991qjFSXvKkAAACyCBUAAEAWoQIAAMgiVAAAAFmECgAAIItQAQAAZLFStg5tuOGGhXveeeedZP2ee+7JHYd2YNCgQcl6jx49wp4lS5Yk65VW7EXeeOONwj3VNnXq1GT9jDPOCHt++tOfJusDBgwIe66++upk/ZNPPqkwXesUremlskMOOSQ8q+ZK0EqfE60lnTFjRthz4YUXZs9E/fn444+T9aeeeqrwsyZPnhye3XHHHcn68OHDw57ddtut8AzVNHDgwPBs9OjRyfrvf//7Gk3T8rypAAAAsggVAABAFqECAADIIlQAAABZhAoAACCL7U91aMSIEYV7rr322uoPQptSaZPT8ccfX/h5V111VbI+Z86cws+qB0uXLk3WK92t//zP/0zW99hjj7Dn8MMPL/w5rVW0UYvKTjvttGb5nFmzZoVnZ511VrL+9NNPhz3Rnwm0btHPyY477ljVz+ndu3eyftNNN4U9Lb39qZKLL744Wa/05+K0adNqNU6z8KYCAADIIlQAAABZhAoAACCLUAEAAGQRKgAAgCxCBQAAkMVK2To0cODAwj1vvfVW9QehTTnllFPCsy5duiTrzz33XNhz5plnZs/UGlS6W9H63C9+8YthT3S/2+JKWerb7rvv3tIj0AqsvvrqyXq1VwgfeuihyXrXrl2r+jnVtHjx4vDswgsvTNZb+9rYSrypAAAAsggVAABAFqECAADIIlQAAABZhAoAACCL7U8tZOjQoeFZtOng/fffD3tsjuHz7LfffoV7FixYEJ7Nnz8/Z5w24amnnkrWt91227BnvfXWq9E0UEyfPn0K94wZM6YGk1DPunfvnqwfffTRzTxJy5kyZUqyftFFF4U9Y8eOrdU4dcubCgAAIItQAQAAZBEqAACALEIFAACQRagAAACyCBUAAEAWK2VbSLQ2tlQqlRoaGpL1iy++OOz58MMPs2eibdh9992T9U033bTwsy6//PLccdq0YcOGJesHHnhg2PO1r30tWe/fv3/Y8+CDDxYbDGrkjTfeaOkRoNk9+eSTyXp7XBtbiTcVAABAFqECAADIIlQAAABZhAoAACCLUAEAAGSx/amFdOrUKTyLtj+NGDGiRtPQlqy77rrJerlcDnvmzZuXrE+aNKkqM7U3lb7WS5cubcZJoFRaZZVVkvWOHeN/AsyaNStZ/8c//lGNkaihV155JTybP39+st69e/dajZOt0saxP//5z8n6TjvtFPb07t07eybSvKkAAACyCBUAAEAWoQIAAMgiVAAAAFmECgAAIItQAQAAZLFStsa6du2arP/oRz8Keyqto4TPM2jQoMI9H3/8cbIerZXkX0499dRkvUePHmHPu+++m6y//vrrVZkJPm3vvfdO1lddddWwJ7r7s2fPrspM1M7EiRPDsx122CFZ//KXvxz2HHfccYVn+NKXvpSsV1p3++STTybro0aNCntefvnlZP3mm28Oe5qyUnadddZJ1ldYYYWwZ+HChYU/p7XzpgIAAMgiVAAAAFmECgAAIItQAQAAZBEqAACALLY/1di3v/3tZL1nz55hT7QdBmrlqquuaukR6tbyyy8fng0ZMiRZ79ChQ9hz6623JuvTpk0rNhjU0FNPPdXSI1AD0Z8zlf78GTduXOHP2XDDDZP1f/7zn2HP0qVLC39O5Pzzzw/PunTpkqwPHDgw7Nl3332T9a222irsmTx5cnjWVnlTAQAAZBEqAACALEIFAACQRagAAACyCBUAAEAWoQIAAMhipWyNHXjggYV7Ro4cWYNJILbaaqu19AgtLlode8kll4Q9W2yxRbL+6quvhj0///nPiw0GNbLccvF/V5w0aVIzTkJb8/LLL7fo50+dOjU8e+2116r2OSeeeGJ4ZqUsAABAQUIFAACQRagAAACyCBUAAEAWoQIAAMhi+1ONbbTRRoV7rr322hpMQnvxu9/9LlkfMGBA2HPssccm63feeWfYc9999xUbrM4NGzYsWf/+979f+Fn7779/eNbSW1Fof9Zdd91kfenSpWFPuVyu1TjQohYvXly1Z3Xo0CE8i7arVbp3rZ03FQAAQBahAgAAyCJUAAAAWYQKAAAgi1ABAABkESoAAIAsVsq2kLFjx4ZnH330UTNOQlsza9asZL3SisiOHdN/FPzkJz8Jex555JFk/YMPPgh7qrmmsnPnzuHZgQcemKxXWqtbaQ1s5PTTT0/Wn3vuucLPgloZNGhQS48AdSP6c/vkk08u/KyBAweGZ1tvvXWy/vjjjxf+nNbCmwoAACCLUAEAAGQRKgAAgCxCBQAAkEWoAAAAstj+VAXrrrtueLbSSisl67Nnzw57lixZkj0T7deECROS9UmTJoU9u+yyS6F6qVQqzZs3L1n/7W9/G/bcddddyfrUqVPDniOPPDJZ33PPPcOejTfeODyLRPfuoosuCnuuu+66ZH3p0qWFPx+AtmP77bdP1m1/AgAACAgVAABAFqECAADIIlQAAABZhAoAACCLUAEAAGSxUrYKorVhpVKptMYaazTjJBA75JBDwrPx48cn601ZzXrwwQc36ayohoaG8Oyxxx5L1u+///6wJ/oaTJ48udhgANStRYsWJeuXXnpp2HPyyScX/pzzzz+/cM/ll19euKeeeFMBAABkESoAAIAsQgUAAJBFqAAAALIIFQAAQBbbn6pg3Lhx4dn06dObbxCoYPbs2eHZLrvskqwfdNBBYU+fPn2S9aFDh4Y9Xbt2Dc+KOuecc8KzCy64IFn/8MMPq/b5ALQ+5XI5Wa+0/emYY45J1iv9ndalS5dk/aijjgp7bH8CAADaNaECAADIIlQAAABZhAoAACCLUAEAAGQRKgAAgCxWylbBRx99FJ5NmjQpWd96663Dnk6dOiXrixYtKjYYNNK7776brF911VWFn3XyySfnjgNU0ZQpU5L1bbfdNuyJzq6//vqwZ8mSJYXmgnoya9as8OzXv/51sn7iiSfWapxWyZsKAAAgi1ABAABkESoAAIAsQgUAAJBFqAAAALLY/lRjRxxxREuPAEA7ds899yTrxx57bNgzdOjQZP3+++8Pe2699dZig0Er8Y9//KOlR2gVvKkAAACyCBUAAEAWoQIAAMgiVAAAAFmECgAAIItQAQAAZLFSFgDasGil7DvvvBP29OzZM1k/5JBDwh4rZWmrHn300WT9xhtvDHsOO+ywZP3uu++uykz1yJsKAAAgi1ABAABkESoAAIAsQgUAAJBFqAAAALI0lMvlcqN+YUNDrWeBZtfIH//PcB9oi9yH9uX8888Pz0499dRk/Zxzzgl7RowYkTtSXXEfYJnG3AdvKgAAgCxCBQAAkEWoAAAAsggVAABAFqECAADIIlQAAABZGr1SFgAAIMWbCgAAIItQAQAAZBEqAACALEIFAACQRagAAACyCBUAAEAWoQIAAMgiVAAAAFmECgAAIItQAQAAZBEqAACALEIFAACQRagAAACyCBUAAEAWoQIAAMjSsbG/sKGhoZZzQIsol8tN6nMfaIvcB1jGfYBlGnMfvKkAAACyCBUAAEAWoQIAAMgiVAAAAFmECgAAIItQAQAAZBEqAACALEIFAACQRagAAACyCBUAAEAWoQIAAMgiVAAAAFmECgAAIItQAQAAZBEqAACALEIFAACQRagAAACyCBUAAEAWoQIAAMgiVAAAAFmECgAAIItQAQAAZBEqAACALEIFAACQpWNLD9BebbzxxuHZ8ccfn6x/61vfCntWX331ZL2hoSHsKZfLyfqf//znsGefffZJ1hctWhT2ALRXAwYMCM/GjRuXrB977LFhT/fu3ZP1Xr16FRvsc4wePTpZf/PNN8Oe1157raozAK2LNxUAAEAWoQIAAMgiVAAAAFmECgAAIItQAQAAZGkoRyuAPv0LK2wRau/WX3/98OwHP/hBsj506NCwZ8UVVyw8w/z585P1aFNIUx1xxBHJ+o033ljVz2kujfzx/wz3oeVFd6tUKpV22223ZL1r165hz+67756s33vvvWHPCy+8kKxPmTIl7Jk4cWKyPnPmzLCnubgP1ffqq6+GZ+uss06y3tTvQyT6/lT7c4YNG5asjxo1qqqf01za033YaqutwrOBAwcm6z179gx7br/99mR90KBBheYqlUqlyZMnF+6p9DnR76cp2zL79+8f9jz00EPhWWvUmPvgTQUAAJBFqAAAALIIFQAAQBahAgAAyCJUAAAAWYQKAAAgi5WyVfCPf/wjPPvyl79c+HlLly5N1j/44IOw58QTT0zWTzjhhLBnyy23LDZYqVS68847k/VoRVupFP9+6kF7WhlYD1ZaaaVkfbvttgt7Nt9882T9oosuCnuqvSqzmhYsWJCsn3TSSWHPmDFjkvWFCxdWY6T/x31oumOPPTZZv+SSS8Kezp07J+tN+T7cdddd4dlf/vKXZH2LLbYIe9Zee+1kfYcddgh7Pvnkk2R9n332CXsefPDB8KyltcX7EK1a/f3vfx/2RF+HpqxgreeeSqtrn3/++WT95ptvDnuasgq3nlkpCwAA1JxQAQAAZBEqAACALEIFAACQRagAAACydGzpAdqCiRMnhmevvPJKsn7dddeFPdF2mHvvvbfYYKVSadKkSeHZk08+max379497BkwYECyvsEGG4Q9L730UnhG+3LGGWck6z/60Y8KPyu6J6VSvC3pb3/7W9hz1FFHJeubbbZZscE+R7du3ZL1a6+9Nuzp1atXsv6zn/2sKjPx7/r165esn3nmmWHPjjvumKx36tQp7Hn//feT9Urb9F588cVk/fXXXw97lixZEp5FunbtmqxX2na41lprJev/5//8n7Cnnrc/tUU777xzsl5pW9Lbb7+drFe6Dy3toYceCs+mTZvWjJO0L95UAAAAWYQKAAAgi1ABAABkESoAAIAsQgUAAJBFqAAAALI0lMvlcqN+YYV1Y+3dCiusEJ5FqwFHjx5do2ka77TTTkvWzz333MLP6tOnT3hWzytlG/nj/xnuQ6xnz57h2axZs5L1Dh06hD0ffvhhsn7qqaeGPVdddVV4FolWf6677rphz5AhQ5L1aD1tqVT5z4ui1lxzzao9q1RqX/chWu1bKpVK8+fPT9aXLl1a+HOitbGlUqm02267Jet//etfC39Oc5kxY0Z4ts466yTrjzzySNiz0047Zc9UK23xPhx99NHJeqU/M+fMmZOsR6uuaZsacx+8qQAAALIIFQAAQBahAgAAyCJUAAAAWYQKAAAgS8eWHqAtWLhwYXhWD1ueIh999FFLj0Cdq7QhZ5NNNknWL7300rAn2vL05JNPhj3HHHNM4Z6mWLRoUbL+8ssvhz3nn39+oTr1Y9999w3Poi1PlbafTJ06NVk/7rjjwp563vIUqfQ1iM6asjWL2rjmmmuS9Z/+9KdhT7TRb5dddgl7HnrooWKD0SZ4UwEAAGQRKgAAgCxCBQAAkEWoAAAAsggVAABAFqECAADIYqVsG7fKKquEZ5tttlnzDUKrdOCBB4Zn1113XeHn3X333cn6KaecEva88MILhT8HPs8tt9wSnvXu3TtZX2ONNcKe4cOHJ+sLFiwoNlidWHfddZP1FVZYofCzXnzxxdxxqLHDDjssPLvrrruS9YEDB4Y9Vsq2T95UAAAAWYQKAAAgi1ABAABkESoAAIAsQgUAAJDF9qc2bu+99w7PDj/88MLPe+yxx5L1OXPmFH4W9eP2229P1vfaa6+wZ8mSJcn6JZdcEvaMHDkyWV+4cGGF6aB5XXDBBS09Qovbfvvtk/UePXoUfla09Y360dDQUPhs2rRptRqHVsqbCgAAIItQAQAAZBEqAACALEIFAACQRagAAACyCBUAAEAWK2XbiC996UvJ+jXXXFP4WU888UR4NmDAgGR93rx5hT+H+rHHHnsk6507dw57ojWRZ5xxRtizePHiYoMBNVPpfn/9619P1iutHp0/f36y/ve//73YYDS7gQMHhmflcjlZ79u3b42mydeUf/uQz5sKAAAgi1ABAABkESoAAIAsQgUAAJBFqAAAALI0lKP/Wf+nf2GFjQ80j44d42VdY8eOTdb322+/sCfa1BFtkiqVSqW33347PGuNGvnj/xmt8T5suumm4Vm08Wv55Zcv/DmHHnpoeDZ69OjCz6P5tKf7QKm0/fbbh2eTJ08u/Lxo4873v//9ws+qB+3pPlx99dXh2VFHHZWsV/p9Rl+75uqZO3du2HPeeecl6zfffHPYM2fOnPCsvWjMffCmAgAAyCJUAAAAWYQKAAAgi1ABAABkESoAAIAsQgUAAJAl3lFK3TnjjDPCs2h1bKVVbIsXL07W29raWP5l6tSp4dmRRx6ZrO+///5hz5AhQ5L1G2+8Mew5+eSTk/Vzzjkn7Bk3blx4BjTdQQcdVNXnvfjii1V9HvUhWiW6zz77hD0DBw5M1keNGlX483v27Fn4c44++uiw5+c//3myfsghh4Q9e++9d7Lu30v/zpsKAAAgi1ABAABkESoAAIAsQgUAAJBFqAAAALI0lKP/Wf+nf2GFLUIU17Vr1/As2kBwxRVXhD2dOnVK1r/2ta+FPe+8806yPnv27LCnrWnkj/9ntJf7sOaaa4Zn0TayShtlVl111WS90tcz+h5FzyqVSqV58+aFZ8Tch8q22mqr8KxPnz7Jeq9evcKefv36JetbbLFF2HPLLbck63fffXfY061bt2R99OjRYc8KK6wQnkWiO7lgwYLCz6oH7ek+VNqw9JWvfCVZnzx5cq3GyVbp93PDDTck63vttVfY8/zzzyfrlbZy3n777eFZa9SY++BNBQAAkEWoAAAAsggVAABAFqECAADIIlQAAABZhAoAACCLlbI11rFjx2T9oosuCnt+8IMfJOuVvlW//vWvk/Xjjjsu7Fm8eHF41l60p5WBzWXjjTcOzy677LJkvdIKzWhN5aOPPhr2DBw4MFmfM2dO2EP7ug/ROtdSqVS68cYbk/U777wz7HnxxReT9ejP5lKpVBo6dGiyXmmV85FHHpms9+jRI+yJvj9N+X4PGjQoPLvjjjsKP6+etaf7QKl0zjnnhGennXZasr5w4cKw57zzzkvWzz///GKD1QkrZQEAgJoTKgAAgCxCBQAAkEWoAAAAsggVAABAlna7/alTp07J+p577hn2HHzwwcl6hw4dwp71118/Wd9mm23i4QIff/xxeDZ48OBkvdKGnEWLFiXr8+fPLzZYK2a7R32INtqUSvH2nErfgwMOOCBZHzduXLHB2pnWeh/69OkTnh144IHJ+oQJE8KeSn9utrTNNtssWZ84cWLY061bt2S9Kd/v6O+0UqlUmjlzZuHn1bPWeh+ovmjr2a9+9auwZ7XVVkvWo61QpVK8GerDDz+sMF3zsP0JAACoOaECAADIIlQAAABZhAoAACCLUAEAAGQRKgAAgCwdW3qAalh55ZWT9QsuuCDsiVawrrrqqlWZqRY6d+4cnt1xxx3JeqX1sB999FGyfvPNN4c9o0aNStanTZsW9sDnmTJlSngW/QwvXbo07Hn++eezZ6L+9O3bN1m/7bbbwp4jjjgiWX/yySerMlMtRKsoS6VS6Re/+EWyvtJKK9VoGuD2229P1mfMmBH23HXXXcn6T37yk7An+rdUpX+X1RNvKgAAgCxCBQAAkEWoAAAAsggVAABAFqECAADI0lAul8uN+oUNDbWepaJKmy2izUe77rprjaZpvGhzTaVNTosXL07WK32rmmvzxwcffJCsjxgxIuy5+OKLazRNvkb++H9GS9+Htmb//fcPz6KtG9OnTw97Ntxww9yR2qV6vw/RnyU777xz2BNtjFq0aFFVZsrRr1+/ZH3QoEFhz/HHH1/4c6LvT1O+33fffXd4Vuket0b1fh9onSptLox+5jp06FCrcRqtMffBmwoAACCLUAEAAGQRKgAAgCxCBQAAkEWoAAAAsggVAABAlrpbKdutW7dk/Q9/+EPY079//xpN8+/mzp2brJ944olhz3333Zesr7POOmHP+++/n6x/8sknYc83vvGNZP2yyy4Lezp16hSeFfXaa6+FZ717967a51SblYHNa++9907WL7300rDny1/+crJupWz11ft9eOKJJ5L1SnNHK2U//vjjsKdjx47J+pprrhn2fOlLX0rWK/3dFf1915Tvw1133RWejRw5svDz7r333mS9R48eYU/0c3DnnXeGPWeffXay/tJLL4U97733XnhWTfV+H+pZtBY5WhHenpxzzjnh2WmnnZasDx48OOxprq+plbIAAEDNCRUAAEAWoQIAAMgiVAAAAFmECgAAIEvdbX86/PDDk/Xrr7++WT5/2rRp4dl2222XrC9YsKBW42Tr0qVLeLbyyisn67fddlvYE22TuuOOO8Kejz76KDxraa11u8exxx4bnk2YMCFZ/8pXvhL2RJvNevXqFfYMGDAgWY82kZVK8babSj+nixcvTtb32WefsOeBBx4Iz4jV+32I/pyp9LPw4IMPJuvvvPNO2NO1a9dkPdpe1lTRRr9K25LGjBmTrFfa/rRw4cJig5XiDYXDhg0Le6K/v6N7X0ml388hhxxS+HlNUe/3oaU999xz4Vn0902HDh1qNU6bMGXKlGR91KhRYc8111xTq3H+je1PAABAzQkVAABAFqECAADIIlQAAABZhAoAACCLUAEAAGTp2NIDfNo3v/nNqj1r0aJF4dns2bOT9W222Sbs+eCDD7Jnam6V1rlGZzvttFOtxqFKonXApVK8inH99dev0TT5Kq1lHjJkSLJubWz7c/fddyfrlVbK9u/fv/DnRCtBm7JitNJq1JEjRybrTz75ZOHPqbaZM2cm66effnrYE622XGmllcKe6Gv9wgsvVJiOelBpTXl0Vy655JKwJ1rp/9BDDxXuqQcbbbRRsl7pDkU9rYU3FQAAQBahAgAAyCJUAAAAWYQKAAAgi1ABAABkaSg3cp1FtKGhKbbccsvwLNrucd9994U9u+yyS7J+1llnhT1/+tOfkvXXX3897KHtaco2l1Kpuveh2nr06JGsjx07NuyJNn516NChKjP9r6effjpZrzTbueeeW9UZiNX7fejYMb2wsFevXmHPQQcdlKyvscYaYc+kSZOS9aZsZar0d8qSJUsKP4/mU+/3oaUNGjQoPLvhhhuS9RVXXDHsib7elb6eUc/cuXPDnttuuy08Kyr692epFG/HWm65+L/nR38Xfutb3yo2WA005j54UwEAAGQRKgAAgCxCBQAAkEWoAAAAsggVAABAFqECAADI0iIrZaFetKeVgSuvvHJ4tsoqqyTr++yzT9jTp0+fZH3UqFFhz2uvvZasL1iwIOyh+bSn+wCfx31ouo022ihZ7927d9gzcODAGk3z76JVuD179gx7op+FyZMnhz3PP/98sl7p78hp06Yl6x9++GHY01yslAUAAGpOqAAAALIIFQAAQBahAgAAyCJUAAAAWWx/ol2z3QOWcR9gGfcBlrH9CQAAqDmhAgAAyCJUAAAAWYQKAAAgi1ABAABkESoAAIAsQgUAAJBFqAAAALIIFQAAQBahAgAAyCJUAAAAWYQKAAAgi1ABAABkESoAAIAsQgUAAJBFqAAAALIIFQAAQBahAgAAyCJUAAAAWRrK5XK5pYcAAABaL28qAACALEIFAACQRagAAACyCBUAAEAWoQIAAMgiVAAAAFmECgAAIItQAQAAZBEqAACALEIFAACQRagAAACyCBUAAEAWoQIAAMgiVAAAAFk6NvYXNjQ01HIOaBHlcrlJfe4DbZH7AMu4D7BMY+6DNxUAAEAWoQIAAMgiVAAAAFmECgAAIItQAQAAZBEqAACALEIFAACQRagAAACyCBUAAEAWoQIAAMgiVAAAAFmECgAAIItQAQAAZBEqAACALEIFAACQRagAAACyCBUAAEAWoQIAAMgiVAAAAFmECgAAIItQAQAAZBEqAACALEIFAACQRagAAACydGzpAerNCSecEJ717ds3WR8yZEitxvk3N9xwQ3h27rnnJusvvPBCrcaBFjVq1Kjw7LbbbkvW77nnnlqNA4WNGDEiWe/Xr1/hZ02cOLFwz4QJE5p0Bs2pZ8+e4dnJJ5+crL/55pthz2WXXZY9E2neVAAAAFmECgAAIItQAQAAZBEqAACALEIFAACQpaFcLpcb9QsbGmo9S9Vtvvnm4dn999+frPfo0aNG09TWkiVLkvVf/vKXYU+0NaE9aeSP/2e0xvvQWq2//vrJ+l//+tewZ/r06cn6VlttVYWJ2i73oemiTU7Dhw9v3kEKqLThaeTIkYV72hr3oT4ceuih4dmNN96YrP/3f/932HPcccdlz9QeNeY+eFMBAABkESoAAIAsQgUAAJBFqAAAALIIFQAAQBahAgAAyNKxpQeopR122CE8i1bHTps2Ley5+OKLk/WePXuGPWussUZ4FvnmN7+ZrK+zzjphT4cOHZL1E044Iex59NFHk/UxY8ZUmA6a16677pqsr7zyymHPWmutVaNpaM+itbGlUsuvjo1WwJZK8WzR3ap0Zl0qze2mm24Kz37zm9804yR8Hm8qAACALEIFAACQRagAAACyCBUAAEAWoQIAAMjSprc/nXbaaeHZDTfckKyfccYZYc/MmTOzZ2qMaFPH+uuvH/b84Q9/KNyz4447Juu2P1FPttpqq5YegXYm2nxU7Q1PEyZMSNb79+9f1c/p169fsl5p+xO0ZptvvnlLj9AueVMBAABkESoAAIAsQgUAAJBFqAAAALIIFQAAQBahAgAAyNJQLpfLjfqFDQ21nqXqevXqFZ7NmTMnWV+yZEmtxqmpnXbaKVmfNGlS2BP9Xg877LCw55Zbbik2WJ1r5I//Z7TG+9BaXXHFFcn6sGHDwp7ofq+55ppVmamtch8qe/DBB8OzpqxnjVbHRqtmq60p3++RI0eGZyNGjMiYpv64D/Xvk08+SdYrfe86depUq3HatMbcB28qAACALEIFAACQRagAAACyCBUAAEAWoQIAAMjSsaUHqKU33nijpUdoNgsWLCjc06FDh2R9hRVWyB0Haq7ShhXbV6iFSpuPou1PlTY5NdeWp0il38/w4cOT9X79+tVqHKCV86YCAADIIlQAAABZhAoAACCLUAEAAGQRKgAAgCxCBQAAkKVNr5Rta3bZZZfwbNttty38vJkzZybrt912W+FnQXMrl8tNOoOmqrQCtr2sMY5W5wJ4UwEAAGQRKgAAgCxCBQAAkEWoAAAAsggVAABAFtufCthrr72S9Ysuuqiqn3P//fcn60OHDg17VlpppcKf88wzzyTr8+bNK/wsqJWmbDaDHCNGjEjWhw8fXvhZ7WUrVKkUf92iOtC2eFMBAABkESoAAIAsQgUAAJBFqAAAALIIFQAAQBahAgAAyGKl7Kf84Ac/CM9OOOGEZH2DDTao6gybbrppVZ8XeeKJJ5rlc+DzrL322uHZ1ltvnayXy+WwZ/z48dkz0X7169evcM+ECROqP0iNVZq5KetzgfbNmwoAACCLUAEAAGQRKgAAgCxCBQAAkEWoAAAAstj+9CknnXRSeNa7d+/mG6QZnHrqqcn6ZpttFvYMHDiwRtPQno0ePbqqzzvvvPOq+jzal1133bVwz8SJE6s/SI21xo1VQP3ypgIAAMgiVAAAAFmECgAAIItQAQAAZBEqAACALEIFAACQxUrZT3niiSfCs5kzZxZ+3tVXX52sz549u/CzKlljjTWS9SuuuCLsWW211ZL1HXfcMezp1atXsv7GG29UmA4qW3XVVcOz5ZZL/7ePMWPGhD0vvPBC9ky0bU1ZGws0v4022ig8a2hoSNafffbZWo1DBd5UAAAAWYQKAAAgi1ABAABkESoAAIAsQgUAAJDF9qdPGTx4cEuPUFVvv/12eHbLLbck66uvvnrYc9tttyXrlTZGwf/6whe+kKx379497Fm6dGmtxqEdq/b2pwkTJlT1ecC/LF68uHDPww8/XINJ+DzeVAAAAFmECgAAIItQAQAAZBEqAACALEIFAACQRagAAACyNJTL5XKjfmFDQ61noZndeOONyfohhxwS9sydOzdZ79mzZ1Vmam6N/PH/DPehaaI1nvfff3/YE32t99lnn7Bn/PjxhebiX9yHf2nK18HXoFTq379/st5a1+26D/Xvk08+Sdavv/76sOeoo46q0TRtW2PugzcVAABAFqECAADIIlQAAABZhAoAACCLUAEAAGTp2NID1NKqq64annXp0iVZf/3112s1Tt0ZM2ZMsl5p+1OHDh2S9Upf63fffbfYYLRZe+65Z+GemTNnJutPPvlk7jhQNSNGjChUrwfVnq21bnmivq299trhWbRp64gjjgh7bH+qHW8qAACALEIFAACQRagAAACyCBUAAEAWoQIAAMgiVAAAAFnaxErZlVdeOVm//fbbw55oRdmZZ54Z9txyyy3FBqtzs2fPLtyzyiqrJOuHHXZY2HP55ZcX/hxarx49eoRnw4YNK/y8v/zlL8n6nDlzCj8LWKZfv36Fe6yNpbm999574Vm5XG6+Qfhc3lQAAABZhAoAACCLUAEAAGQRKgAAgCxCBQAAkKVNbH868sgjk/Vddtml8LMGDRoUnj333HPJ+qxZs8KeuXPnFp6hKVZbbbVkvUuXLmHP6aefXqtxaMc6doz/WOnevXvh502ePDlnHChs5MiRyfrw4cPDnqZsUmouDz74YLK+6667Fn5W9LWBWvnggw9aegQayZsKAAAgi1ABAABkESoAAIAsQgUAAJBFqAAAALIIFQAAQJY2sVL2z3/+c7I+Z86csKdnz57J+uDBg8Oe6Gz69Olhz/jx48OzavrGN76RrPfu3buqnzN69OhkPfoe0P4ccMAB4Vm5XC78vJdeeilnHGgW0XrWSmtbJ0yYULXPj9bGft4MRVVzZqBt8aYCAADIIlQAAABZhAoAACCLUAEAAGQRKgAAgCwN5UauY2loaKj1LFU3dOjQ8Ozyyy9P1rt06VKrcVqNefPmhWc777xzsj516tRajVNTTdlGVCq1zvtQbdFdGTt2bNiz1157JesLFy4Me7p161ZsMJrMffiXaFtSpQ1LTTFy5MjCPf369UvWq7nhqVQqlfr375+st6ftT+5D/fvkk0+S9Urfu06dOtVqnDatMffBmwoAACCLUAEAAGQRKgAAgCxCBQAAkEWoAAAAsggVAABAlja9UraSTTfdNFm/7777wp4vfOELyXo9f20qfXvfeuutZP3ss88Oe6666qrsmeqJlYFNN3jw4GR99OjRhZ915plnhmfnn39+4efRNO5DZZXWtlZ73WxziNbGlkrta3VsxH2ofxMnTkzWo/X3pVKpdPjhhyfrN910U1VmaquslAUAAGpOqAAAALIIFQAAQBahAgAAyCJUAAAAWTq29AAtZerUqcn6mmuuGfYMGzYsWe/Ro0fYc+yxxybra6+9doXp0m644Ybw7MUXX0zW586dG/ZcffXVhWeA//Xyyy8n60888UTYs9ZaayXrv/nNb6oyE9RSpY1I0Sal4cOHhz2VtkkVNXLkyPBsxIgRVfscqCdHHHFEsv6LX/wi7OnQoUONpsGbCgAAIItQAQAAZBEqAACALEIFAACQRagAAACyCBUAAECWhnK5XG7UL2xoqPUs0Owa+eP/Ge4DbZH7AMu4D7BMY+6DNxUAAEAWoQIAAMgiVAAAAFmECgAAIItQAQAAZBEqAACALEIFAACQRagAAACyCBUAAEAWoQIAAMgiVAAAAFmECgAAIItQAQAAZBEqAACALEIFAACQRagAAACyCBUAAEAWoQIAAMgiVAAAAFmECgAAIItQAQAAZBEqAACALEIFAACQRagAAACyCBUAAECWhnK5XG7pIQAAgNbLmwoAACCLUAEAAGQRKgAAgCxCBQAAkEWoAAAAsggVAABAFqECAADIIlQAAABZhAoAACDL/wVsFk7pak0XywAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x800 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a figure to display the images\n",
    "fig, axes = plt.subplots(4, 4, figsize=(8, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.imshow(data[i], cmap='gray')\n",
    "    ax.axis('off')  # Turn off axis\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf48db96-cbca-4e70-9d08-f2e8b4df72a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw prediction result:\n",
      "[[-2014.11608887 -1311.47106934     0.          -809.42236328\n",
      "  -2184.89770508 -2214.63891602 -2563.9765625   -855.1920166\n",
      "  -1562.55480957 -2256.29321289]\n",
      " [-1171.41137695  -845.31536865  -852.75        -778.46356201\n",
      "      0.          -640.11688232  -732.66070557  -745.90026855\n",
      "   -677.30493164  -396.33096313]\n",
      " [-2623.24853516 -1792.17126465 -2053.03393555 -1972.52197266\n",
      "      0.         -1453.83752441 -1374.40783691 -2165.27319336\n",
      "  -1597.01281738 -1043.95458984]\n",
      " [-1107.73876953 -1147.88317871  -835.63568115  -683.32830811\n",
      "  -1169.68945312  -497.76721191 -1078.1607666  -1316.04907227\n",
      "      0.          -893.53710938]\n",
      " [-1665.18200684     0.          -931.99420166 -1256.90588379\n",
      "   -822.97467041  -920.72894287 -1028.39196777  -987.26220703\n",
      "   -949.96142578 -1308.67053223]\n",
      " [    0.         -3020.39648438 -1527.64990234 -2057.19238281\n",
      "  -2421.42407227 -2261.72314453 -1632.88110352 -1942.8182373\n",
      "  -1558.79638672 -1720.40258789]\n",
      " [-1974.42822266 -1857.70605469 -1165.95300293 -1040.06762695\n",
      "  -1633.32177734 -1828.83398438 -2663.96972656     0.\n",
      "  -1489.81262207  -808.58947754]\n",
      " [-1339.4597168  -1417.1628418  -1131.90551758  -573.777771\n",
      "   -392.39666748  -786.1385498  -1326.03039551  -551.93823242\n",
      "   -875.6027832      0.        ]\n",
      " [-2088.51660156 -1325.18969727     0.         -1108.45214844\n",
      "  -2510.27758789 -2311.19091797 -2427.38989258 -1326.43432617\n",
      "  -1650.04016113 -2761.44189453]\n",
      " [-1361.72717285 -2274.14038086 -2367.67285156 -1422.37939453\n",
      "  -1833.44995117     0.         -1285.12524414 -1987.77783203\n",
      "  -1128.94030762 -1136.57421875]\n",
      " [-1578.45617676 -1553.21716309     0.         -1045.55932617\n",
      "  -1970.58215332 -2187.63012695 -2169.78051758 -1237.4753418\n",
      "  -1502.01989746 -2204.43457031]\n",
      " [ -771.36187744 -1234.45544434 -1195.96008301  -517.35754395\n",
      "   -914.1161499      0.          -779.22869873 -1118.31884766\n",
      "   -564.95288086  -576.94415283]\n",
      " [-2231.94238281 -1867.37182617 -1404.62988281     0.\n",
      "  -2018.56848145 -1183.90869141 -2524.48901367 -1576.41711426\n",
      "  -1698.90136719 -1584.30627441]\n",
      " [-1830.81030273     0.          -996.95709229 -1354.8347168\n",
      "   -952.01068115 -1006.1149292  -1113.10583496 -1085.43664551\n",
      "  -1057.87756348 -1467.63427734]\n",
      " [    0.         -1679.81079102  -484.77618408 -1137.75927734\n",
      "  -1375.73754883 -1606.79919434 -1117.59240723 -1083.51416016\n",
      "   -877.61749268 -1119.12817383]\n",
      " [-1738.7010498      0.          -928.72686768 -1181.01293945\n",
      "   -957.3314209   -931.10357666 -1137.66430664  -920.53979492\n",
      "  -1056.26855469 -1371.52075195]]\n",
      "\n",
      "Most likely answer: [2 4 4 8 1 0 7 9 2 5 2 5 3 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "response = predictor.predict(np.expand_dims(data, axis=1))\n",
    "print(\"Raw prediction result:\")\n",
    "print(response)\n",
    "print()\n",
    "\n",
    "print(\"Most likely answer: {}\".format(response.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0104ab-b577-4832-b8f9-4b16c7d9189f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
